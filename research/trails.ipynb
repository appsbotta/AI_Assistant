{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Appsb\\\\Desktop\\\\AI_Assistant\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Appsb\\\\Desktop\\\\AI_Assistant'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    github_url: str\n",
    "    linkedin_url: str\n",
    "    local_data_file: Path\n",
    "    save_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.constants import *\n",
    "from bot.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.WindowsPath"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_path = CONFIG_PATH,\n",
    "            params_path = PARAMS_PATH\n",
    "        ):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.param = read_yaml(params_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_ingestion_config(self)->DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            github_url=config.github_url,\n",
    "            linkedin_url=config.linkedin_url,\n",
    "            local_data_file=config.local_data_file,\n",
    "            save_dir=config.save_dir\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bot import logger\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import json\n",
    "import zipfile\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self,config:DataIngestionConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_repos(self):\n",
    "        logger.info(f\"Starting writing data from git hub repos\")\n",
    "        url = self.config.github_url\n",
    "        headers = {\"Authorization\": f\"token {os.getenv('TOKEN')}\"}\n",
    "        repos = requests.get(url, headers=headers).json()\n",
    "        save_dir = self.config.save_dir\n",
    "        with open(os.path.join(save_dir,\"data.json\"),'w',encoding='utf-8') as f:\n",
    "            json.dump(repos,f,indent=4)\n",
    "        logger.info(f\"Completed writing data from git hub repos\")\n",
    "    \n",
    "    def downloadFiles(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename , headers = request.urlretrieve(\n",
    "                url = self.config.linkedin_url,\n",
    "                filename = self.config.local_data_file\n",
    "            )\n",
    "            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n",
    "        else:\n",
    "            logger.info(f\"file already exists of size\")\n",
    "    \n",
    "    def extractZip(self):\n",
    "        unzip_path = self.config.save_dir\n",
    "        os.makedirs(unzip_path,exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file,'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-17 19:40:41,451: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-17 19:40:41,460: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-17 19:40:41,466: INFO: common: created directory at: artifacts]\n",
      "[2025-03-17 19:40:41,472: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-03-17 19:40:41,475: INFO: 1269584388: Starting writing data from git hub repos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-17 19:40:42,148: INFO: 1269584388: Completed writing data from git hub repos]\n",
      "[2025-03-17 19:40:42,152: INFO: 1269584388: file already exists of size]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.get_repos()\n",
    "    data_ingestion.downloadFiles()\n",
    "    data_ingestion.extractZip()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Appsb\\\\Desktop\\\\AI_Assistant'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTrasformationConfig:\n",
    "    root_dir: Path\n",
    "    file_dir: Path\n",
    "    save_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.constants import *\n",
    "from bot.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_path = CONFIG_PATH,\n",
    "            params_path = PARAMS_PATH\n",
    "        ):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_transformation_config(self)->DataTrasformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_trasformation_config = DataTrasformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            file_dir=config.file_dir,\n",
    "            save_dir=config.save_dir,\n",
    "        )\n",
    "\n",
    "        return data_trasformation_config\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from reportlab.lib.pagesizes import letter,A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Preformatted\n",
    "from bot import logger\n",
    "import json\n",
    "import markdown2\n",
    "import html2text\n",
    "import base64\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"artifacts/data_ingestion\",'data.json'),'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "sorted_repos = sorted(data, \n",
    "                      key=lambda repo: datetime.strptime(repo[\"updated_at\"], \"%Y-%m-%dT%H:%M:%SZ\"), \n",
    "                      reverse=True)\n",
    "# sorted_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self,config:DataTrasformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data(self):\n",
    "        file_dir = self.config.file_dir\n",
    "        for file_name in os.listdir(file_dir):\n",
    "            if file_name.lower().endswith(\".pdf\"):  # Check if file is a PDF\n",
    "                source_path = os.path.join(file_dir, file_name)\n",
    "                destination_path = os.path.join(self.config.save_dir, file_name)\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "        \n",
    "        with open(os.path.join(file_dir,'data.json'),'r',encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    \n",
    "    def get_last_updated(self):\n",
    "        file_dir = self.config.file_dir\n",
    "        with open(os.path.join(file_dir,'data.json'),'r',encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        sorted_repos = sorted(data, \n",
    "                      key=lambda repo: datetime.strptime(repo[\"updated_at\"], \"%Y-%m-%dT%H:%M:%SZ\"), \n",
    "                      reverse=True)\n",
    "        return sorted_repos\n",
    "    \n",
    "    def get_lang(self,repo_name):\n",
    "        url = f'https://api.github.com/repos/appsbotta/{repo_name}/languages'\n",
    "        headers = {\"Authorization\": f\"token {os.getenv('TOKEN')}\"}\n",
    "        lang = requests.get(url,headers=headers).json()\n",
    "        top_three_keys = sorted(lang, key=lang.get, reverse=True)[:3]\n",
    "        # logger.info(f\"Got top 3 languages used in {repo_name}\")\n",
    "        return top_three_keys\n",
    "    \n",
    "    def get_timings(self,repo):\n",
    "        update = repo['updated_at'][:10]\n",
    "        created = repo['created_at'][:10]\n",
    "        pushed = repo['pushed_at'][:10]\n",
    "        times = {\n",
    "            \"updated_at\": update,\n",
    "            \"created_at\":created,\n",
    "            \"pushed_at\": pushed,\n",
    "        }\n",
    "        # logger.info(f\"secured 3 timings {times.keys()}\")\n",
    "        return times\n",
    "    \n",
    "    def get_readme(self,OWNER,REPO):\n",
    "        # logger.info(f\"requeting readme file for the repo {REPO} \")\n",
    "        readme = f\"https://api.github.com/repos/{OWNER}/{REPO}/readme\"\n",
    "        headers = {\"Authorization\": f\"token {os.getenv('TOKEN')}\"}\n",
    "        response = requests.get(readme,headers=headers)\n",
    "        readme_content = \"No Readme FIle\"\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            readme_content = base64.b64decode(data[\"content\"]).decode(\"utf-8\")\n",
    "            readme_content =  markdown2.markdown(readme_content, extras=[\"strip\"])\n",
    "            readme_content = html2text.html2text(readme_content)\n",
    "        # logger.info(f\"Request for README file for the repo {REPO} completed\")\n",
    "        return readme_content\n",
    "            \n",
    "    def get_pdf_from_data(self):\n",
    "        logger.info(\"Saving data to a pdf file started\")\n",
    "        save_dir = self.config.save_dir\n",
    "        data = self.get_data()\n",
    "\n",
    "        doc = SimpleDocTemplate(os.path.join(save_dir,'repo.pdf'), pagesize=A4)\n",
    "        doc1 = SimpleDocTemplate(os.path.join(save_dir,'last.pdf'), pagesize=A4)\n",
    "        styles = getSampleStyleSheet()\n",
    "        custom_style = ParagraphStyle(\n",
    "            'Custom',\n",
    "            parent=styles['Normal'],\n",
    "            fontName='Courier',\n",
    "            fontSize=10,\n",
    "            leading=14,  # Line height\n",
    "            spaceAfter=5,\n",
    "        )\n",
    "        heading_style = ParagraphStyle(\n",
    "            \"HeadingStyle\",\n",
    "            parent=styles[\"Heading1\"],\n",
    "            fontName=\"Courier-Bold\",\n",
    "            fontSize=14,\n",
    "            leading=22,\n",
    "\n",
    "        )\n",
    "\n",
    "        content = []\n",
    "        \n",
    "        sorted_repos = self.get_last_updated()\n",
    "        for i,repo in enumerate(sorted_repos):\n",
    "            time = datetime.strptime(repo[\"updated_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            text = f\"{repo['name']} last Updated at {time}\"\n",
    "            paragraph = Paragraph(text,custom_style)\n",
    "            content.append(paragraph)\n",
    "        doc1.build(content)\n",
    "        content = []\n",
    "\n",
    "\n",
    "        for i,repo in enumerate(data):\n",
    "            text = f\"{i+1}. <b>{repo['name']}</b>  --->   {repo['html_url']} \\n\"\n",
    "            # text = text + str(i+1) + \". \" +  str(repo[\"name\"]) + \" -> \" + str(repo[\"html_url\"]) +\"\\n\"\n",
    "            paragraph = Paragraph(text,custom_style)\n",
    "            content.append(paragraph)\n",
    "        content.append(Spacer(1,5))\n",
    "        \n",
    "        for i,repo in enumerate(data):\n",
    "            OWNER = repo['owner']['login']\n",
    "            REPO = repo['name']\n",
    "            readme = self.get_readme(OWNER,REPO)\n",
    "            timings = self.get_timings(repo)\n",
    "            lang = self.get_lang(REPO)\n",
    "            heading = Paragraph(REPO,heading_style)\n",
    "            content.append(heading)\n",
    "            for key,value in timings.items():\n",
    "                text = f\"{key} -> {value}\"\n",
    "                paragraph = Paragraph(text,custom_style)\n",
    "                content.append(paragraph)\n",
    "            lang_text = \"   \"\n",
    "            for it in lang:\n",
    "                lang_text = lang_text + it +\", \"\n",
    "            text = Paragraph(lang_text,custom_style)\n",
    "            content.append(text)\n",
    "            readme = Preformatted(readme,custom_style)\n",
    "            content.append(readme)\n",
    "            content.append(Spacer(1, 5))\n",
    "\n",
    "\n",
    "        doc.build(content)\n",
    "        logger.info(\"saving data to a pdf file is completed\")\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-17 19:41:16,177: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-17 19:41:16,183: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-17 19:41:16,188: INFO: common: created directory at: artifacts]\n",
      "[2025-03-17 19:41:16,194: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-03-17 19:41:16,198: INFO: 538437088: Saving data to a pdf file started]\n",
      "[2025-03-17 19:41:38,885: INFO: 538437088: saving data to a pdf file is completed]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.get_pdf_from_data()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Appsb\\\\Desktop\\\\AI_Assistant'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Appsb\\\\Desktop'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:16+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:16+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\last.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Portifolio last Updated at 2025-03-17 10:53:09\\nAI_Assistant last Updated at 2025-03-17 06:23:46\\nDataSets last Updated at 2025-03-16 16:15:56\\nText-Summarizer last Updated at 2025-03-16 14:30:46\\nLlamaindex last Updated at 2025-03-14 14:54:48\\nCrewAI last Updated at 2025-03-13 10:41:10\\nLangChain last Updated at 2025-03-12 07:26:04\\nQ-A_ChatBot_with_Implementation last Updated at 2025-03-11 14:50:44\\nAgenticAi last Updated at 2025-03-10 01:52:18\\nAWS_BEDROCK last Updated at 2025-03-07 03:27:03\\nKidney_diease_end_to_end last Updated at 2025-03-05 13:55:46\\nDL-End_to_End last Updated at 2025-03-05 11:42:04\\nstudent_performance last Updated at 2025-03-02 12:08:46\\nSimpleDVC last Updated at 2025-02-24 10:17:22\\nGemini last Updated at 2025-02-16 15:30:21\\nSentimentAnalysis last Updated at 2024-11-09 10:48:19\\nImageCaption last Updated at 2024-08-04 13:32:24\\nNetworks last Updated at 2024-05-25 02:45:05\\nJosaaDataAnalysis last Updated at 2023-08-28 13:46:23\\nFitnessTracker last Updated at 2023-08-27 13:35:23\\nVideo_Web last Updated at 2023-08-26 17:42:41\\nOlX_CLONE last Updated at 2023-08-26 17:17:42\\nStockPrediction last Updated at 2023-08-24 14:48:30\\nTelecom_Churn_Prediction last Updated at 2023-08-23 14:24:50\\nFaceDetection_React last Updated at 2023-08-19 16:47:01\\nMarket_Basket last Updated at 2023-08-15 12:15:14\\nReal-Time-chatting last Updated at 2022-06-30 05:18:21'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-03-16T21:43:37+05:30', 'title': 'Resume', 'author': 'LinkedIn', 'subject': 'Resume generated from profile', 'moddate': '2025-03-16T21:43:37+05:30', 'source': 'artifacts\\\\data_transformation\\\\Profile.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content=\"Contact \\n \\n  \\nappsbotta@gmail.com \\nwww.linkedin.com/in/lokesh548 \\n9 \\n( \\nLinkedIn \\n) \\nTop Skills \\nNatural Language Processing \\nMachine Learning \\nDeep Learning \\nCI/CD pipelines \\nLokesh Apparao Botta \\nData Science | Agentic AI | NLP | IIT Guwahati'24 \\nNarsipatnam, Andhra Pradesh, India \\nSummary \\nI am graduate in electronics and communications engineering at IIT \\nGuwahati, one of the premier institutes of technology in India. I have \\na strong academic background and Deep Learning and Machine \\nLearning skills. My areas of interest are Natural Language Process, \\nLarge language models and generative AI. I aspire to pursue a \\ncareer in these domains, and contribute to the advancement of \\nscience and technology. Along with this i have a working experience \\nas a research intern. \\nExperience \\nIndian Institute of Technology, Guwahati \\nResearch Intern \\nMay 2023 - March 2024  \\n  months \\n) \\n(11 \\nGuwahati, Assam, India \\n- \\nEngaged in research and projects alongside Professor Sukumar Nandi. \\nDeveloping a graph based algorithm for resource allocation for Device-to \\n- \\n- \\nDevice communication for better Quality of Service for both cellular and D2D \\nusers. \\nEducation \\nIndian Institute of Technology, Guwahati \\nBachelor of Technology - B.Tech, Electrical, Electronics and Communications \\nEngineering \\n · (November 2020 - July 2024) \\nSri Chaitanya College of Education \\nIntermediate \\n · (2018 - 2020) \\nSri Chaitanya College of Education \\n10 \\nth,SSC \\n · (July 2017 - March 2018) \\n  \\n Page  \\n1 \\n of  \\n1\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 0, 'page_label': '1'}, page_content='1. AgenticAi ---> https://github.com/appsbotta/AgenticAi\\n2. AI_Assistant ---> https://github.com/appsbotta/AI_Assistant\\n3. AWS_BEDROCK ---> https://github.com/appsbotta/AWS_BEDROCK\\n4. CrewAI ---> https://github.com/appsbotta/CrewAI\\n5. DataSets ---> https://github.com/appsbotta/DataSets\\n6. DL-End_to_End ---> https://github.com/appsbotta/DL-End_to_End\\n7. FaceDetection_React --->\\nhttps://github.com/appsbotta/FaceDetection_React\\n8. FitnessTracker ---> https://github.com/appsbotta/FitnessTracker\\n9. Gemini ---> https://github.com/appsbotta/Gemini\\n10. ImageCaption ---> https://github.com/appsbotta/ImageCaption\\n11. JosaaDataAnalysis ---> https://github.com/appsbotta/JosaaDataAnalysis\\n12. Kidney_diease_end_to_end --->\\nhttps://github.com/appsbotta/Kidney_diease_end_to_end\\n13. LangChain ---> https://github.com/appsbotta/LangChain\\n14. Llamaindex ---> https://github.com/appsbotta/Llamaindex\\n15. Market_Basket ---> https://github.com/appsbotta/Market_Basket\\n16. Networks ---> https://github.com/appsbotta/Networks\\n17. OlX_CLONE ---> https://github.com/appsbotta/OlX_CLONE\\n18. Portifolio ---> https://github.com/appsbotta/Portifolio\\n19. Q-A_ChatBot_with_Implementation --->\\nhttps://github.com/appsbotta/Q-A_ChatBot_with_Implementation\\n20. Real-Time-chatting --->\\nhttps://github.com/appsbotta/Real-Time-chatting\\n21. SentimentAnalysis ---> https://github.com/appsbotta/SentimentAnalysis\\n22. SimpleDVC ---> https://github.com/appsbotta/SimpleDVC\\n23. StockPrediction ---> https://github.com/appsbotta/StockPrediction\\n24. student_performance --->\\nhttps://github.com/appsbotta/student_performance\\n25. Telecom_Churn_Prediction --->\\nhttps://github.com/appsbotta/Telecom_Churn_Prediction\\n26. Text-Summarizer ---> https://github.com/appsbotta/Text-Summarizer\\n27. Video_Web ---> https://github.com/appsbotta/Video_Web\\nAgenticAi\\nupdated_at -> 2025-03-10\\ncreated_at -> 2025-01-13\\npushed_at -> 2025-03-10'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 1, 'page_label': '2'}, page_content='Python,\\nNo Readme FIle\\nAI_Assistant\\nupdated_at -> 2025-03-17\\ncreated_at -> 2025-03-09\\npushed_at -> 2025-03-17\\nJupyter Notebook, Python, HTML,\\n# AI Assistant\\nAWS_BEDROCK\\nupdated_at -> 2025-03-07\\ncreated_at -> 2025-03-06\\npushed_at -> 2025-03-07\\nPython,\\n# AWS_BEDROCK\\n# to run this\\n## 1\\\\. Git clone the repo\\n## 2\\\\. Install requirements.txt\\n## 3\\\\. Create an IAM user with Administrtor access\\n## 4\\\\. Configure AWS in cli\\n`bash aws configure `\\nCrewAI\\nupdated_at -> 2025-03-13\\ncreated_at -> 2025-03-13\\npushed_at -> 2025-03-13\\nPython,\\n# CrewAI\\nDataSets\\nupdated_at -> 2025-03-16\\ncreated_at -> 2023-08-27\\npushed_at -> 2025-03-16'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 2, 'page_label': '3'}, page_content='Jupyter Notebook,\\nNo Readme FIle\\nDL-End_to_End\\nupdated_at -> 2025-03-05\\ncreated_at -> 2025-03-02\\npushed_at -> 2025-03-05\\nJupyter Notebook, Python, HTML,\\n# DL-End _to_ End\\n## Workflow\\n  1. Update config.yaml in config dir\\n  2. Update secrets.yaml [optional]\\n  3. Update params.yaml\\n  4. Update the entity\\n  5. Update the configuration manager in src config\\n  6. Update the components\\n  7. Update the pipeline\\n  8. Update the main.py\\n  9. Update the dvc.yaml\\n# To run the repo\\n## steps\\nClone the repository `bash https://github.com/appsbotta/DL-End_to_End `\\n## step - 01 Create a conda env after opening the repo\\n`bash conda create -n ckn python=3.13 -y ` `bash conda activate ckn `\\n## step - 02 Install Requirements.txt\\n`bash pip install -r requirements.txt `\\n## step - 03 Run app.py\\n`bash python app.py `\\n## DVC cmd\\n  * dvc init\\n  * dvc repro\\n  * dvc dag\\n# AWS CI-CD Deployment using Github Actions'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 3, 'page_label': '4'}, page_content='## 1\\\\. Login to AWS Console\\n## 2\\\\. Create IAM user for deployment\\n```bash\\n# give these access to IAM user\\n  1. EC2 access -> this is virtual machine\\n  2. ECR: Elastic COntainer registery to save your docker image in aws\\n# About deployment\\n  1. build docker image of the source code\\n  2. Push your docker image to ECR\\n  3. Launch your EC2 instance\\n  4. Pull your image from ECR to EC2\\n  5. Launch your docker image in EC2\\n# policy\\n  1. AmazonEC2ContainerRegistryFullAccess\\n  2. AmazonEC2FullAccess\\n```\\n## 3\\\\. Create ECR repo to store /dave docker image\\n`bash copy the repo uri ex : 022499019910.dkr.ecr.us-\\neast-1.amazonaws.com/chicken `\\n## 4\\\\. Create an EC2 machine Instance(Ubuntu)\\n## 5\\\\. Connect EC2 instance and install docker\\n```bash\\n# optinal\\nsudo apt-get update -y\\nsudo apt-get upgrade\\n# required'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 4, 'page_label': '5'}, page_content=\"curl -fsSL https://get.docker.com -o get-docker.sh\\nsudo sh get-docker.sh\\nsudo usermod -aG docker ubuntu\\nnewgrp docker ```\\n## 6\\\\. create a self runner in github repo settings\\n`bash in settings under action/runner create a new runner. a. while running\\nthe cmds in order when asked for runner group keep it default but for runner\\nname use self-hosted `\\n## 7\\\\. Setup github secrets\\n```bash AWS _ACCESS_ KEY_ID=\\nAWS _SECRET_ ACCESS_KEY=\\nAWS_REGION = us-east-1\\nAWS _ECR_ LOGIN_URI = ''(for example it will be 022499019910.dkr.ecr.us-\\neast-1.amazonaws.com)\\nECR _REPOSITORY_ NAME = '' (example chicken as last part of ECR uri)\\nFaceDetection_React\\nupdated_at -> 2023-08-19\\ncreated_at -> 2023-08-19\\npushed_at -> 2023-08-19\\nJavaScript, HTML, CSS,\\n# facedetection\\nFitnessTracker\\nupdated_at -> 2023-08-27\\ncreated_at -> 2023-08-27\\npushed_at -> 2023-08-27\\nJavaScript, HTML, CSS,\\n# Fitness Tracker\\n## Description\\nThis is a Fitness Tracker built using MERN stack. It facilitates one to add\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 5, 'page_label': '6'}, page_content='users and record their date and duration of performing particular fitness\\nactivity.Activity can also be deleted. This web application is built using\\nMongoDB,Express,Nodejs,React and Material UI. Images used in this application\\nare being taken from [Unsplash website](https://unsplash.com).\\n## Demo\\n■ [Link](https://serene-volhard-1843cb.netlify.app/)\\nBackend Heroku Link-https://fitness-tracker-mern.herokuapp.com/\\n[Users](https://fitness-tracker-mern.herokuapp.com/users)\\n[Exercises](https://fitness-tracker-mern.herokuapp.com/exercises)\\n## Screenshots\\nHomepage ![fitkit_home](https://user-\\nimages.githubusercontent.com/4997491/117522296-20021d80-afd0-11eb-8079-922a4d51925a.JPG)\\nCreate user ![fitkit_user](https://user-\\nimages.githubusercontent.com/4997491/117525054-3911cb00-afde-11eb-97b5-a468f17935de.JPG)\\nRecord Fitness Activity ![fitkit_exercise](https://user-\\nimages.githubusercontent.com/4997491/117525061-3d3de880-afde-11eb-9201-acdb5b804f40.JPG)\\nFitness Activity Dashboard ![fitkit_dashboard](https://user-\\nimages.githubusercontent.com/4997491/117525087-652d4c00-afde-11eb-92d4-0fda6f5c5d03.JPG)\\n404 Error page ![error](https://user-\\nimages.githubusercontent.com/4997491/117525227-dcfb7680-afde-11eb-9434-a8f93c5b76d7.JPG)\\n## Available Scripts\\nIn the project directory, you can run:\\n`npm start`\\nRuns the app in the development mode.  \\nOpen <http://localhost:3000> to view it in the browser.\\nGemini\\nupdated_at -> 2025-02-16\\ncreated_at -> 2025-01-16\\npushed_at -> 2025-02-16\\nPython,'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 6, 'page_label': '7'}, page_content='No Readme FIle\\nImageCaption\\nupdated_at -> 2024-08-04\\ncreated_at -> 2023-06-20\\npushed_at -> 2024-08-04\\nPython, HTML,\\n# image-caption-generator\\n## Deployed Link\\n[Image Caption](https://image-caption-gen-deploy-1.streamlit.app/)\\n# Home page\\n![Screenshot \\\\(82\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/33837fd6-2e5a-4329-9038-5034fecc4e11)\\n# Upon selecting caption predictor\\n![Screenshot \\\\(470\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/20c43357-01e9-4c5d-94ad-6182d370a625)\\n# Sample Images\\n![Screenshot \\\\(28\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/f6fe65e4-964e-48f0-98ef-703cdd872750) ![Screenshot\\n\\\\(27\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/492b7abd-e277-4e06-b2d0-a8ffef509597)\\nJosaaDataAnalysis\\nupdated_at -> 2023-08-28\\ncreated_at -> 2023-08-28\\npushed_at -> 2023-08-28\\nHTML, Python, CSS,\\n# JOSAA-data-analysis\\nThis project aims to create a portal that allows users to explore the seat\\nallotment statistics of JOSAA (Joint Seat Allocation Authority) from 2016 to\\n2022. The project involves web scraping data from the JOSAA website,\\nperforming data cleaning and analysis, and presenting the insights through\\nvisualizations on a website frontend. The website presents the findings\\nthrough interactive charts and tables, enabling users to gain valuable\\ninsights into the trends and patterns of seat allotments over the years.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 7, 'page_label': '8'}, page_content=\"## Tech Stack/Frameworks:\\n  * Frontend: HTML, CSS, JavaScript\\n  * Backend: Django\\n  * Database: SQLite\\n  * Data Scraping: Beautiful Soup\\n  * Data Cleaning: NumPy, Pandas\\n  * Data Visualization: Chart.js\\n## Command to run the project locally\\n  * python manage.py runserver\\n  * Then run the server locally on port 8000\\n## Home page\\nThe home page of the JOSAA Analysis portal provides a user-friendly interface\\nto explore and analyze the JOSAA seat allotment statistics. It offers several\\ninsightful sections to delve into the data and gain valuable information.\\nHere's a breakdown of each section: \\\\- View Institute wise cut-off \\\\- Analyze\\ninstitute wise cut-off trends \\\\- Roundwise cut-off Analysis\\n  * ![home](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/1d752e47-ef2d-4b4c-bf66-77fc8817c09d)\\n## View Institute wise cut-off list page\\n  * Upon clicking this option, a list of all IITs is shown along with their NIRF ranking(2023), Location and their established year. So the users can select specific institutes and explore the corresponding cut-off data.\\n  * ![iit list](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/f4f562e1-c93b-48a5-a114-4c321b296fe6)\\n    * ### For each IIT \\n      * By selecting a specific IIT, users can explore the trends and changes in the cut-off ranks throughout the various rounds of the seat allocation process over the years 2016 to 2022.\\n      * It can further narrow down their search by choosing specific programs offered by the selected institutes along with seat type and gender.\\n      * This feature helps users understand the cut-off trends for different programs in their preferred institutes.\\n      * ![first graph](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/5c411f78-ea17-4218-a0d6-9a8740ad78b5)\\n## Analyze institute wise cut-off trends\\n  * Institute trends highlight the trends of various programs offered by a particular institute over the years. This helps understand the popularity and perception of programs offered by the institute, and thus helps understand the demand for a particular program in the institute during the counselling process.\\n  * ![Screenshot \\\\(20\\\\)](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/45d3feab-6bf4-4611-91fb-91580b6a90ce)\\n  * Upon sleecting the gender, branch and institute, user will get the cut-off analysis for each branch present at that IIT.\\n  * ![Screenshot \\\\(22\\\\)](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/1db046fe-c44c-4627-8282-c8143bf0a88a)\\n## Roundwise cut-off Analysis\\n  * Round trends highlight the general trend of closing ranks throughout the rounds of the counselling process. This helps understand the likely range of changes to the closing ranks throught the counselling proces.\\n  * Users can get the round wise analysis at each IIT by selecting the gender,seat type and branch.\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 8, 'page_label': '9'}, page_content='* User can change the college name by clicking on \"Go to iit-list\" buttion.\\n  * ![Screenshot \\\\(25\\\\)](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/3206dd19-d8fb-4e88-ace9-84a743db723e)\\nKidney_diease_end_to_end\\nupdated_at -> 2025-03-05\\ncreated_at -> 2025-03-05\\npushed_at -> 2025-03-05\\nPython, Jupyter Notebook,\\n# Kidney _diease_ end _to_ end\\n## Workflow\\n  1. Update config.yaml in config dir\\n  2. Update secrets.yaml [optional]\\n  3. Update params.yaml\\n  4. Update the entity\\n  5. Update the configuration manager in src config\\n  6. Update the components\\n  7. Update the pipeline\\n  8. Update the main.py\\n  9. Update the dvc.yaml\\n# To run the repo\\n## steps\\nClone the repository `bash\\nhttps://github.com/appsbotta/Kidney_diease_end_to_end `\\n## step - 01 Create a conda env after opening the repo\\n`bash conda create -n ckn python=3.8 -y ` `bash conda activate ckn `\\n## step - 02 Install Requirements.txt\\n`bash pip install -r requirements.txt `\\n## step - 03 Run app.py\\n`bash python app.py `\\n## DVC cmd\\n  * dvc init\\n  * dvc repro\\n  * dvc dag'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 9, 'page_label': '10'}, page_content='# AWS CI-CD Deployment using Github Actions\\n## 1\\\\. Login to AWS Console\\n## 2\\\\. Create IAM user for deployment\\n```bash\\n# give these access to IAM user\\n  1. EC2 access -> this is virtual machine\\n  2. ECR: Elastic COntainer registery to save your docker image in aws\\n# About deployment\\n  1. build docker image of the source code\\n  2. Push your docker image to ECR\\n  3. Launch your EC2 instance\\n  4. Pull your image from ECR to EC2\\n  5. Launch your docker image in EC2\\n# policy\\n  1. AmazonEC2ContainerRegistryFullAccess\\n  2. AmazonEC2FullAccess\\n```\\nLangChain\\nupdated_at -> 2025-03-12\\ncreated_at -> 2025-01-13\\npushed_at -> 2025-03-12\\nJupyter Notebook, Python,\\n# LangChain Projects\\nThis repository showcases various applications and experiments utilizing the\\nLangChain framework, which is designed for building applications powered by\\nlarge language models (LLMs).\\n## Table of Contents\\n  * Projects'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 10, 'page_label': '11'}, page_content='* LLMAPP\\n    * PdfQuery\\n    * ChatMultipleDocs\\n    * TextSummarization\\n    * Celebrity.py\\n  * Installation\\n  * Usage\\n  * Contributing\\n  * License\\n## Projects\\n### LLMAPP\\nA project demonstrating the integration of LangChain with large language\\nmodels to build intelligent applications.\\n### PdfQuery\\nAn application that utilizes LangChain to extract and process information from\\nPDF documents.\\n### ChatMultipleDocs\\nA chatbot implementation capable of interacting with multiple documents,\\npowered by LangChain.\\n### TextSummarization\\nA tool that leverages LangChain to provide text summarization capabilities.\\n### Celebrity.py\\nA script that explores web to get the data related to a Celebrity given his\\nname and any 5 major events happend around his DOB\\n## Installation\\n  1. **Clone the repository:**\\n```bash git clone https://github.com/appsbotta/LangChain.git cd LangChain\\n  2. **Create a virtual environment:**\\n```bash conda create -p myenv python conda activate path/to/myenv\\n  3. **Install the required dependencies:**\\n```bash pip install -r requirements.txt'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 11, 'page_label': '12'}, page_content='4. **Create a`.env` file in the root of the repository:**\\nAdd your API keys to the .env file ```bash touch .env\\n## Usage\\nEach project is contained within its respective directory. Navigate to the\\ndesired project folder and follow the instructions provided above\\nLlamaindex\\nupdated_at -> 2025-03-14\\ncreated_at -> 2025-01-17\\npushed_at -> 2025-03-14\\nJupyter Notebook,\\n# Llamaindex\\nMarket_Basket\\nupdated_at -> 2023-08-15\\ncreated_at -> 2023-08-15\\npushed_at -> 2023-08-15\\nJupyter Notebook,\\n# Market_Basket\\nThis notebook has been executed on kaggle. To view the notebook and run it,\\nhttps://www.kaggle.com/code/lokesh5489/market-basket To view the concerned\\ndataset, visit https://www.kaggle.com/code/lokesh5489/market-basket/data\\nUsed Aprior algorithm to find relation between two products\\nNetworks\\nupdated_at -> 2024-05-25\\ncreated_at -> 2024-05-23\\npushed_at -> 2024-05-25\\nC++, HTML, C,\\n# # The Network Simulator, Version 3\\n## Changes that we made\\n### 1.lte-ue-mac.cc\\n  * added one pre-defined table for type-0 allocation at line 52\\n  * Added Pf in line 404'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 12, 'page_label': '13'}, page_content='* Added function to get rbg size at line 503\\n  * line 2482 for grant printing in random allocation\\n  * line 2532 code for PF allocation, CQI calculation,mcs from cqi\\n  * added function at line 2715\\n### 2.lte-sl-out-of-covrg-comm.cc\\n  * At line 268 added code to print from rrc\\n  * At line 412 added code to print from mac\\nOlX_CLONE\\nupdated_at -> 2023-08-26\\ncreated_at -> 2023-08-26\\npushed_at -> 2023-08-26\\nJavaScript, CSS, HTML,\\n# OLX _clone_ IITG\\n## About the website\\nUsers are directed to login page on opening the website. Users have to login\\nusing their Outlook Id. Later user will be directed to home page of the\\nwebsite where two buttons will be displayed. Here user can choose whether to\\nbuy or sell and based on that available categories will be diplayed. Profile\\nshows logged in users profile. Logout button logs out the user.\\n## Environment Setup Locally\\n  * Install React\\n  * Use npm install in both Backend and Client \\n  * ...\\n## Tech Stack Used\\n  * React\\n  * MongoDB\\n  * Express\\n  * Node\\n  * HTML\\n  * CSS\\n  * Javascript\\n## Key Features\\n  * User can login and logout using Outlook Id\\n  * Functionality to buy and sell\\n  * Seller Profile Containing all the products he want to sell and stats of every deal he made, like people who are interested with listed money'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 13, 'page_label': '14'}, page_content='* Search functionality for buyer and filter method to get his wanted product within the desired price range\\n  * Product details along with buyer details\\n  * Option to agree to listed deal or to reach out seller for some negotiation for a particular product\\n  * Marks product as sold if deal is made\\n## Login page\\n  * The web application is authenticated and user must sign in using Outlook Id. ![image](https://user-images.githubusercontent.com/95306028/177820740-33b49604-b1b1-4285-bc41-9b9a5bf5b1ce.png)\\n## Home page\\n  * After login the home page will be displayed, where user can choose to buy or sell items. ![image](https://user-images.githubusercontent.com/95306028/177821314-90828c2c-6ef6-4644-9729-df123930b31c.png)\\n## Buyer Homepage\\n  * After clicking **Buy** all categories which are available are displayed. User can also search for required item in search bar.\\n  * ![image](https://user-images.githubusercontent.com/95306028/177822651-b505f91e-2f11-4826-951c-e6e6e0560d97.png)\\nPortifolio\\nupdated_at -> 2025-03-17\\ncreated_at -> 2025-01-18\\npushed_at -> 2025-03-17\\nJavaScript, HTML, CSS,\\n# Portifolio\\nQ-A_ChatBot_with_Implementation\\nupdated_at -> 2025-03-11\\ncreated_at -> 2025-01-07\\npushed_at -> 2025-03-11\\nPython,\\n* * *\\ntitle: LangChain ChatBot emoji: ■ colorFrom: gray colorTo: blue sdk: streamlit\\nsdk _version: 1.41.1 app_ file: app.py\\n## pinned: false\\nReal-Time-chatting\\nupdated_at -> 2022-06-30\\ncreated_at -> 2022-06-30\\npushed_at -> 2022-07-07\\nHTML, CSS, JavaScript,'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 14, 'page_label': '15'}, page_content=\"# Real-Time-chatting\\nUser are directed to opening page where ther need to click 'Enter ChatRoom',\\nUpon Clicking it users are redirected to a page where they need to enter then\\nroom,upon that the user will enter into chat room where he can chat with his\\nother buddies!!\\n## Enviroment Setup Locally\\n  * Install Web Sockets and Expressjs\\n  * Run the server and Connect to Port 500\\n## Tech Stack Used\\n  * HTML\\n  * JavaScript\\n  * Css\\n  * WebSockets\\n## Opening Page\\n  * This the Page we get when we Open localhost in port 5000\\n![OPENING](https://user-\\nimages.githubusercontent.com/75985363/177767489-6a32f337-8b3c-4281-a281-1d58c24ae3e0.jpg)\\n## Name Entry\\n  * User need to enter his name ![entering name](https://user-images.githubusercontent.com/75985363/177767789-5137808d-a34a-4bed-b415-b3ab67a61fca.jpg)\\n## Chat Room\\n  * After entering name User redirects to this page ![chat room](https://user-images.githubusercontent.com/75985363/177767981-0893a5eb-7aa2-4421-8bd1-da9592eeb46d.jpg)\\nSentimentAnalysis\\nupdated_at -> 2024-11-09\\ncreated_at -> 2024-11-09\\npushed_at -> 2024-11-09\\n# SentimentAnalysis\\nSimpleDVC\\nupdated_at -> 2025-02-24\\ncreated_at -> 2025-02-21\\npushed_at -> 2025-02-24\\nPython, Jupyter Notebook, HTML,\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 15, 'page_label': '16'}, page_content='# WorkFlow of the Project\\n  1. Create env `bash conda create -p myenv python -y `\\n  2. activate env `bash conda activate (path to myenv) `\\n  3. Create Requirements.txt\\n  4. Install requirements.txt `bash pip install -r requirements.txt `\\n  5. Initilize git `bash git init `\\n  6. Initilize DVC `bash dvc init `\\n  7. Add data to DVC `bash dvc add data_given/winequality.csv `\\n  8. `bash git add . && git commit -m \"first commit\" git push origin main `\\n  9. Create params.yaml\\n  10. create get _data.py and load_ data.py to get data and add the load_data stage to dvc.yaml\\n  11. create split _data.py to split data and add the split_ data stage to dvc.yaml\\n  12. create train _and_ evaluate.py to train & evaluate model and add the train _and_ evaluate stage to dvc.yaml\\n  13. Tox `bash tox tox -r #for rebuilding use this else only tox `\\n  14. pytest `bash pytest -v `\\n  15. setup command `bash pip install -e . `\\n  16. build your own package `bash python setup.py sdist bdist_wheel `\\n  17. create the need webapp structure\\n  18. Create app.py \\n  19. Add github action workflow\\n  20. Create an articat folder\\n  21. MLflow server command `bash mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 -p 1234 `\\nStockPrediction\\nupdated_at -> 2023-08-24\\ncreated_at -> 2023-08-24'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 16, 'page_label': '17'}, page_content='pushed_at -> 2023-08-24\\nJupyter Notebook,\\n# StockPrediction\\nThis notebook has been executed on kaggle. To view the notebook and run it,\\nvisit : https://www.kaggle.com/code/lokesh5489/stock\\nstudent_performance\\nupdated_at -> 2025-03-02\\ncreated_at -> 2025-02-28\\npushed_at -> 2025-03-02\\nJupyter Notebook, Python, HTML,\\n# End to End ML Project (student_performance)\\n## workflow\\n  1. created setup.py, template.py and requirements.txt\\n  2. Created custom exception in exception.py and logger.py and a function to read yaml\\n  3. created EDA and Model trainer in research\\n  4. Add new config.yaml file and done data_ingestion\\n  5. Completed data transformation\\n  6. Model Training\\n  7. Created the prediction pipeline and the Flask app\\n  8. Created .ebextensions for deployment\\n  9. create .github actions\\n  10. create ECR repo and save the repo uri \\n  11. create a ec2 instance \\n  12. Create a iam user and save a access key\\n  13. In github, in settings under action/runner create a new runner. a. while running the cmds in order when asked for runner group keep it default but for runner name use self-hosted\\n  14. Create Secret keys in github which are in workflow\\n## Docker Setup In EC2 commands to be Executed'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 17, 'page_label': '18'}, page_content='# optinal\\n  1. sudo apt-get update -y\\n  2. sudo apt-get upgrade\\n# required\\n  1. curl -fsSL https://get.docker.com -o get-docker.sh\\n  2. sudo sh get-docker.sh\\n  3. sudo usermod -aG docker ubuntu\\n  4. newgrp docker \\n## To run\\n  1. Create a virtual env and activate it `bash conda create -p env python y conda activate /path/to/env `\\n  2. Install requirements.txt `bash pip install -r requirements.txt `\\nTelecom_Churn_Prediction\\nupdated_at -> 2023-08-23\\ncreated_at -> 2023-08-23\\npushed_at -> 2024-02-14\\nJupyter Notebook,\\n# Telecom _Churn_ Prediction\\nThis notebook has been executed on kaggle for utilising its GPU feature. To\\nview the dataset, visit https://www.kaggle.com/code/lokesh5489/telecomm-\\nchurn/data To visit the notebook, visit\\nhttps://www.kaggle.com/code/lokesh5489/telecomm-churn/notebook\\nText-Summarizer\\nupdated_at -> 2025-03-16\\ncreated_at -> 2024-08-15\\npushed_at -> 2025-03-16\\nJupyter Notebook, Python, Dockerfile,\\n# End-to-End Text-Summarizer\\n## Workflows\\n  1. Update config.yaml'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 18, 'page_label': '19'}, page_content='2. Update params.yaml\\n  3. Update entity\\n  4. Update configuration manager in src/config\\n  5. Update components\\n  6. Update pipeline\\n  7. Update main.py\\n  8. Update app.py\\n# How to run?\\n### STEPS:\\nClone the repository\\n`bash https://github.com/appsbotta/Text-Summarizer.git `\\n### STEP 01- Create a conda environment after opening the repository\\n`bash conda create -n summary python=3.8 -y `\\n`bash conda activate summary `\\n### STEP 02- install the requirements\\n`bash pip install -r requirements.txt `\\n```bash\\n# Finally run the following command\\npython app.py ```\\nNow, `bash open up you local host and port `\\n# AWS-CICD-Deployment-with-Github-Actions\\n## 1\\\\. Login to AWS console.\\n## 2\\\\. Create IAM user for deployment\\n    \\n    \\n    #with specific access\\n    \\n    1. EC2 access : It is virtual machine\\n    \\n    2. ECR: Elastic Container registry to save your docker image in aws\\n    #Description: About the deployment'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 19, 'page_label': '20'}, page_content='1. Build docker image of the source code\\n    \\n    2. Push your docker image to ECR\\n    \\n    3. Launch Your EC2 \\n    \\n    4. Pull Your image from ECR in EC2\\n    \\n    5. Lauch your docker image in EC2\\n    \\n    #Policy:\\n    \\n    1. AmazonEC2ContainerRegistryFullAccess\\n    \\n    2. AmazonEC2FullAccess\\n    \\n## 3\\\\. Create ECR repo to store/save docker image\\n    \\n    \\n    - copy the repo uri\\n    - ex : 022499019910.dkr.ecr.us-east-1.amazonaws.com/text\\n    \\n## 4\\\\. Create EC2 machine (Ubuntu)\\n## 5\\\\. Open EC2 and Install docker in EC2 Machine:\\n    \\n    \\n    #optinal\\n    \\n    sudo apt-get update -y\\n    \\n    sudo apt-get upgrade\\n    \\n    #required\\n    \\n    curl -fsSL https://get.docker.com -o get-docker.sh\\n    \\n    sudo sh get-docker.sh\\n    \\n    sudo usermod -aG docker ubuntu\\n    \\n    newgrp docker\\n# 6\\\\. Configure EC2 as self-hosted runner:\\n    setting>actions>runner>new self hosted runner> choose os> then run command one by one'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 20, 'page_label': '21'}, page_content='# 7\\\\. Setup github secrets:\\n    \\n    \\n    AWS_ACCESS_KEY_ID=\\n    \\n    AWS_SECRET_ACCESS_KEY=\\n    \\n    AWS_REGION = us-east-1\\n    \\n    AWS_ECR_LOGIN_URI =\\'\\'(for example it will be 022499019910.dkr.ecr.us-east-1.amazonaws.com)\\n    \\n    ECR_REPOSITORY_NAME = \\'\\' (example text as last part of ECR uri)\\nVideo_Web\\nupdated_at -> 2023-08-26\\ncreated_at -> 2023-08-26\\npushed_at -> 2023-08-31\\nJavaScript, CSS, HTML,\\n# LuffyMeet - A Video chat web application\\n###  Intro\\nThis is a webRTC based video chatting web application. The users can register\\nand get logged in to their user page. They can either create a new room or use\\ntheir previous rooms to join a call and chat. This implementation also\\nconsists of a real time chat and file share functionality.\\n# Deployed link\\n[noobmeet.herokuapp.com](https://noobmeet.herokuapp.com/)  \\n(Calls and chats are functional, but becasue of NO \"Access-Control-Allow-\\nOrigin\" on icon package script, fonts-awesome is blocked. So u won\\'t be able\\nto access any incall-features in the deployement. To use all the features,\\nfollow the steps in \"Getting Started\" and run it on a local machine, no\\nproblems should arise, but depending on the time, the script source may\\nchange, so u have to manually change the source in local machine)\\n# Features and Functionalities\\n  * Unlimited number of rooms \\n  * Unlimited duration calls \\n  * Multiple participants \\n  * Copy the link and share it with your friends \\n  * Toggling your audio/video stream \\n  * Mute and Hide Everyone'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 21, 'page_label': '22'}, page_content='* Chat and File Share in real-time \\n  * Chat before and after the meeting \\n  * Send individual messages to the participants online in the room \\n  * Screen Sharing \\n  * Recording your stream, audio and video \\n  * Full Screen Mode on double click on the video \\n# ScreenShots\\n  * Login and Register page\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177010820-11f827e8-895b-4274-b568-d997184240d3.png)\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177010848-5471e60c-3261-49a3-9195-a380e0085db2.png)\\n  * Main Page\\n    * Contains all the past rooms in sorted according to the time of thier last update.\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177010985-a214ddf7-6ddb-42d7-8a66-a71e065fa1c4.png)\\n    * Creating a new room\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177011685-74a216e6-e020-4a17-906c-763c3d3c6682.png)\\n  * Call page\\n    * Call Page (videos are just turned off, it is functional)\\n![Screenshot \\\\(1074\\\\)](https://user-\\nimages.githubusercontent.com/72460532/177011233-1c00902c-9047-41ef-9f7f-f220a4bd9d9f.png)\\n    * Automatic pop up of chat box upon recieving an message. The chat box is draggable (hold the body instead of the bar). \\n![image](https://user-\\nimages.githubusercontent.com/72460532/177011335-d0d75476-c963-435b-9c38-a67f9439aab1.png)\\n  * Chat page - Contains all the chats form previous meetings.\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177011551-15db10a1-ece1-4b9e-af36-86899d273424.png)\\nA more detailed description and ScreenShots will be uploaded soon. (With video\\nturned on too :-)).'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 22, 'page_label': '23'}, page_content='# Demo (Not functional as now)\\n  * Open https://noobmeet.herokuapp.com/\\n  * Create an account\\n  * Set a meeting name to create your room\\n  * Click on call button and give access to camera and microphone to join call\\n  * Click on chat button to chat before the meeting starts and as well as after the meeting ends\\n  * Share the room link for others to join \\n# Getting Started\\n  * You need to have Node.js installed\\n  * clone this repo\\n    * git clone https://github.com/fivar-rox/Video_chat.git\\n    * cd video-call\\n  * Install dependencies\\n    * npm init\\n    * npm install\\n  * Start the server \\n    * npm start\\n  * open http://localhost:4000 in your browser\\n# Tech Stack\\n  * Node.js \\n  * Web RTC \\n  * Socket.io \\n  * ngrok and stun-turn server\\n  * Firebase - for database \\n  * Heroku - for hosting'),\n",
       " Document(metadata={'producer': 'Microsoft® Excel® 2016', 'creator': 'Microsoft® Excel® 2016', 'creationdate': '2025-03-16T21:36:55+05:30', 'author': 'Lokesh Apparao Botta', 'moddate': '2025-03-16T21:36:55+05:30', 'source': 'artifacts\\\\data_transformation\\\\Skills.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Skills\\nEnd-to-End Project Management\\nContinuous Integration and Continuous Delivery (CI/CD)\\nAmazon Web Services (AWS)\\nMLOps\\nArtificial Intelligence (AI)\\nLarge Language Models (LLM)\\nAgentic AI\\nGoogle Gemini\\nGenerative AI\\nLangChain\\nNatural Language Processing (NLP)\\nData Science\\nTensorFlow\\nDeep Learning\\nMachine Learning\\nPython (Programming Language)\\nObject-Oriented Programming (OOP)\\nSQL\\nDjango\\npandas\\nNumPy\\nScikit-Learn\\nSoftware Development\\nData Structures\\nAlgorithms\\nMatplotlib\\nC++\\nReact.js\\nComputer networks\\nNode.js\\nCommunication\\nProject Management')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "loader = PyPDFDirectoryLoader(\"artifacts/data_transformation\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:16+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:16+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\last.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Portifolio last Updated at 2025-03-17 10:53:09\\nAI_Assistant last Updated at 2025-03-17 06:23:46\\nDataSets last Updated at 2025-03-16 16:15:56\\nText-Summarizer last Updated at 2025-03-16 14:30:46\\nLlamaindex last Updated at 2025-03-14 14:54:48\\nCrewAI last Updated at 2025-03-13 10:41:10\\nLangChain last Updated at 2025-03-12 07:26:04\\nQ-A_ChatBot_with_Implementation last Updated at 2025-03-11 14:50:44\\nAgenticAi last Updated at 2025-03-10 01:52:18\\nAWS_BEDROCK last Updated at 2025-03-07 03:27:03\\nKidney_diease_end_to_end last Updated at 2025-03-05 13:55:46\\nDL-End_to_End last Updated at 2025-03-05 11:42:04\\nstudent_performance last Updated at 2025-03-02 12:08:46\\nSimpleDVC last Updated at 2025-02-24 10:17:22\\nGemini last Updated at 2025-02-16 15:30:21\\nSentimentAnalysis last Updated at 2024-11-09 10:48:19\\nImageCaption last Updated at 2024-08-04 13:32:24\\nNetworks last Updated at 2024-05-25 02:45:05\\nJosaaDataAnalysis last Updated at 2023-08-28 13:46:23\\nFitnessTracker last Updated at 2023-08-27 13:35:23\\nVideo_Web last Updated at 2023-08-26 17:42:41\\nOlX_CLONE last Updated at 2023-08-26 17:17:42\\nStockPrediction last Updated at 2023-08-24 14:48:30\\nTelecom_Churn_Prediction last Updated at 2023-08-23 14:24:50\\nFaceDetection_React last Updated at 2023-08-19 16:47:01\\nMarket_Basket last Updated at 2023-08-15 12:15:14\\nReal-Time-chatting last Updated at 2022-06-30 05:18:21'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-03-16T21:43:37+05:30', 'title': 'Resume', 'author': 'LinkedIn', 'subject': 'Resume generated from profile', 'moddate': '2025-03-16T21:43:37+05:30', 'source': 'artifacts\\\\data_transformation\\\\Profile.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content=\"Contact \\n \\n  \\nappsbotta@gmail.com \\nwww.linkedin.com/in/lokesh548 \\n9 \\n( \\nLinkedIn \\n) \\nTop Skills \\nNatural Language Processing \\nMachine Learning \\nDeep Learning \\nCI/CD pipelines \\nLokesh Apparao Botta \\nData Science | Agentic AI | NLP | IIT Guwahati'24 \\nNarsipatnam, Andhra Pradesh, India \\nSummary \\nI am graduate in electronics and communications engineering at IIT \\nGuwahati, one of the premier institutes of technology in India. I have \\na strong academic background and Deep Learning and Machine \\nLearning skills. My areas of interest are Natural Language Process, \\nLarge language models and generative AI. I aspire to pursue a \\ncareer in these domains, and contribute to the advancement of \\nscience and technology. Along with this i have a working experience \\nas a research intern. \\nExperience \\nIndian Institute of Technology, Guwahati \\nResearch Intern \\nMay 2023 - March 2024  \\n  months \\n) \\n(11 \\nGuwahati, Assam, India \\n- \\nEngaged in research and projects alongside Professor Sukumar Nandi. \\nDeveloping a graph based algorithm for resource allocation for Device-to \\n- \\n- \\nDevice communication for better Quality of Service for both cellular and D2D \\nusers. \\nEducation \\nIndian Institute of Technology, Guwahati \\nBachelor of Technology - B.Tech, Electrical, Electronics and Communications \\nEngineering \\n · (November 2020 - July 2024) \\nSri Chaitanya College of Education \\nIntermediate \\n · (2018 - 2020) \\nSri Chaitanya College of Education \\n10 \\nth,SSC \\n · (July 2017 - March 2018) \\n  \\n Page  \\n1 \\n of  \\n1\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 0, 'page_label': '1'}, page_content='1. AgenticAi ---> https://github.com/appsbotta/AgenticAi\\n2. AI_Assistant ---> https://github.com/appsbotta/AI_Assistant\\n3. AWS_BEDROCK ---> https://github.com/appsbotta/AWS_BEDROCK\\n4. CrewAI ---> https://github.com/appsbotta/CrewAI\\n5. DataSets ---> https://github.com/appsbotta/DataSets\\n6. DL-End_to_End ---> https://github.com/appsbotta/DL-End_to_End\\n7. FaceDetection_React --->\\nhttps://github.com/appsbotta/FaceDetection_React\\n8. FitnessTracker ---> https://github.com/appsbotta/FitnessTracker\\n9. Gemini ---> https://github.com/appsbotta/Gemini\\n10. ImageCaption ---> https://github.com/appsbotta/ImageCaption\\n11. JosaaDataAnalysis ---> https://github.com/appsbotta/JosaaDataAnalysis\\n12. Kidney_diease_end_to_end --->\\nhttps://github.com/appsbotta/Kidney_diease_end_to_end\\n13. LangChain ---> https://github.com/appsbotta/LangChain\\n14. Llamaindex ---> https://github.com/appsbotta/Llamaindex\\n15. Market_Basket ---> https://github.com/appsbotta/Market_Basket\\n16. Networks ---> https://github.com/appsbotta/Networks\\n17. OlX_CLONE ---> https://github.com/appsbotta/OlX_CLONE\\n18. Portifolio ---> https://github.com/appsbotta/Portifolio\\n19. Q-A_ChatBot_with_Implementation --->\\nhttps://github.com/appsbotta/Q-A_ChatBot_with_Implementation\\n20. Real-Time-chatting --->\\nhttps://github.com/appsbotta/Real-Time-chatting\\n21. SentimentAnalysis ---> https://github.com/appsbotta/SentimentAnalysis\\n22. SimpleDVC ---> https://github.com/appsbotta/SimpleDVC\\n23. StockPrediction ---> https://github.com/appsbotta/StockPrediction\\n24. student_performance --->\\nhttps://github.com/appsbotta/student_performance\\n25. Telecom_Churn_Prediction --->\\nhttps://github.com/appsbotta/Telecom_Churn_Prediction\\n26. Text-Summarizer ---> https://github.com/appsbotta/Text-Summarizer\\n27. Video_Web ---> https://github.com/appsbotta/Video_Web\\nAgenticAi\\nupdated_at -> 2025-03-10\\ncreated_at -> 2025-01-13\\npushed_at -> 2025-03-10'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 1, 'page_label': '2'}, page_content='Python,\\nNo Readme FIle\\nAI_Assistant\\nupdated_at -> 2025-03-17\\ncreated_at -> 2025-03-09\\npushed_at -> 2025-03-17\\nJupyter Notebook, Python, HTML,\\n# AI Assistant\\nAWS_BEDROCK\\nupdated_at -> 2025-03-07\\ncreated_at -> 2025-03-06\\npushed_at -> 2025-03-07\\nPython,\\n# AWS_BEDROCK\\n# to run this\\n## 1\\\\. Git clone the repo\\n## 2\\\\. Install requirements.txt\\n## 3\\\\. Create an IAM user with Administrtor access\\n## 4\\\\. Configure AWS in cli\\n`bash aws configure `\\nCrewAI\\nupdated_at -> 2025-03-13\\ncreated_at -> 2025-03-13\\npushed_at -> 2025-03-13\\nPython,\\n# CrewAI\\nDataSets\\nupdated_at -> 2025-03-16\\ncreated_at -> 2023-08-27\\npushed_at -> 2025-03-16'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 2, 'page_label': '3'}, page_content='Jupyter Notebook,\\nNo Readme FIle\\nDL-End_to_End\\nupdated_at -> 2025-03-05\\ncreated_at -> 2025-03-02\\npushed_at -> 2025-03-05\\nJupyter Notebook, Python, HTML,\\n# DL-End _to_ End\\n## Workflow\\n  1. Update config.yaml in config dir\\n  2. Update secrets.yaml [optional]\\n  3. Update params.yaml\\n  4. Update the entity\\n  5. Update the configuration manager in src config\\n  6. Update the components\\n  7. Update the pipeline\\n  8. Update the main.py\\n  9. Update the dvc.yaml\\n# To run the repo\\n## steps\\nClone the repository `bash https://github.com/appsbotta/DL-End_to_End `\\n## step - 01 Create a conda env after opening the repo\\n`bash conda create -n ckn python=3.13 -y ` `bash conda activate ckn `\\n## step - 02 Install Requirements.txt\\n`bash pip install -r requirements.txt `\\n## step - 03 Run app.py\\n`bash python app.py `\\n## DVC cmd\\n  * dvc init\\n  * dvc repro\\n  * dvc dag\\n# AWS CI-CD Deployment using Github Actions'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 3, 'page_label': '4'}, page_content='## 1\\\\. Login to AWS Console\\n## 2\\\\. Create IAM user for deployment\\n```bash\\n# give these access to IAM user\\n  1. EC2 access -> this is virtual machine\\n  2. ECR: Elastic COntainer registery to save your docker image in aws\\n# About deployment\\n  1. build docker image of the source code\\n  2. Push your docker image to ECR\\n  3. Launch your EC2 instance\\n  4. Pull your image from ECR to EC2\\n  5. Launch your docker image in EC2\\n# policy\\n  1. AmazonEC2ContainerRegistryFullAccess\\n  2. AmazonEC2FullAccess\\n```\\n## 3\\\\. Create ECR repo to store /dave docker image\\n`bash copy the repo uri ex : 022499019910.dkr.ecr.us-\\neast-1.amazonaws.com/chicken `\\n## 4\\\\. Create an EC2 machine Instance(Ubuntu)\\n## 5\\\\. Connect EC2 instance and install docker\\n```bash\\n# optinal\\nsudo apt-get update -y\\nsudo apt-get upgrade\\n# required'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 4, 'page_label': '5'}, page_content=\"curl -fsSL https://get.docker.com -o get-docker.sh\\nsudo sh get-docker.sh\\nsudo usermod -aG docker ubuntu\\nnewgrp docker ```\\n## 6\\\\. create a self runner in github repo settings\\n`bash in settings under action/runner create a new runner. a. while running\\nthe cmds in order when asked for runner group keep it default but for runner\\nname use self-hosted `\\n## 7\\\\. Setup github secrets\\n```bash AWS _ACCESS_ KEY_ID=\\nAWS _SECRET_ ACCESS_KEY=\\nAWS_REGION = us-east-1\\nAWS _ECR_ LOGIN_URI = ''(for example it will be 022499019910.dkr.ecr.us-\\neast-1.amazonaws.com)\\nECR _REPOSITORY_ NAME = '' (example chicken as last part of ECR uri)\\nFaceDetection_React\\nupdated_at -> 2023-08-19\\ncreated_at -> 2023-08-19\\npushed_at -> 2023-08-19\\nJavaScript, HTML, CSS,\\n# facedetection\\nFitnessTracker\\nupdated_at -> 2023-08-27\\ncreated_at -> 2023-08-27\\npushed_at -> 2023-08-27\\nJavaScript, HTML, CSS,\\n# Fitness Tracker\\n## Description\\nThis is a Fitness Tracker built using MERN stack. It facilitates one to add\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 5, 'page_label': '6'}, page_content='users and record their date and duration of performing particular fitness\\nactivity.Activity can also be deleted. This web application is built using\\nMongoDB,Express,Nodejs,React and Material UI. Images used in this application\\nare being taken from [Unsplash website](https://unsplash.com).\\n## Demo\\n■ [Link](https://serene-volhard-1843cb.netlify.app/)\\nBackend Heroku Link-https://fitness-tracker-mern.herokuapp.com/\\n[Users](https://fitness-tracker-mern.herokuapp.com/users)\\n[Exercises](https://fitness-tracker-mern.herokuapp.com/exercises)\\n## Screenshots\\nHomepage ![fitkit_home](https://user-\\nimages.githubusercontent.com/4997491/117522296-20021d80-afd0-11eb-8079-922a4d51925a.JPG)\\nCreate user ![fitkit_user](https://user-\\nimages.githubusercontent.com/4997491/117525054-3911cb00-afde-11eb-97b5-a468f17935de.JPG)\\nRecord Fitness Activity ![fitkit_exercise](https://user-\\nimages.githubusercontent.com/4997491/117525061-3d3de880-afde-11eb-9201-acdb5b804f40.JPG)\\nFitness Activity Dashboard ![fitkit_dashboard](https://user-\\nimages.githubusercontent.com/4997491/117525087-652d4c00-afde-11eb-92d4-0fda6f5c5d03.JPG)\\n404 Error page ![error](https://user-\\nimages.githubusercontent.com/4997491/117525227-dcfb7680-afde-11eb-9434-a8f93c5b76d7.JPG)\\n## Available Scripts\\nIn the project directory, you can run:\\n`npm start`\\nRuns the app in the development mode.  \\nOpen <http://localhost:3000> to view it in the browser.\\nGemini\\nupdated_at -> 2025-02-16\\ncreated_at -> 2025-01-16\\npushed_at -> 2025-02-16\\nPython,'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 6, 'page_label': '7'}, page_content='No Readme FIle\\nImageCaption\\nupdated_at -> 2024-08-04\\ncreated_at -> 2023-06-20\\npushed_at -> 2024-08-04\\nPython, HTML,\\n# image-caption-generator\\n## Deployed Link\\n[Image Caption](https://image-caption-gen-deploy-1.streamlit.app/)\\n# Home page\\n![Screenshot \\\\(82\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/33837fd6-2e5a-4329-9038-5034fecc4e11)\\n# Upon selecting caption predictor\\n![Screenshot \\\\(470\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/20c43357-01e9-4c5d-94ad-6182d370a625)\\n# Sample Images\\n![Screenshot \\\\(28\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/f6fe65e4-964e-48f0-98ef-703cdd872750) ![Screenshot\\n\\\\(27\\\\)](https://github.com/Vidya132/image-caption-\\ngenerator/assets/95306028/492b7abd-e277-4e06-b2d0-a8ffef509597)\\nJosaaDataAnalysis\\nupdated_at -> 2023-08-28\\ncreated_at -> 2023-08-28\\npushed_at -> 2023-08-28\\nHTML, Python, CSS,\\n# JOSAA-data-analysis\\nThis project aims to create a portal that allows users to explore the seat\\nallotment statistics of JOSAA (Joint Seat Allocation Authority) from 2016 to\\n2022. The project involves web scraping data from the JOSAA website,\\nperforming data cleaning and analysis, and presenting the insights through\\nvisualizations on a website frontend. The website presents the findings\\nthrough interactive charts and tables, enabling users to gain valuable\\ninsights into the trends and patterns of seat allotments over the years.'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 7, 'page_label': '8'}, page_content=\"## Tech Stack/Frameworks:\\n  * Frontend: HTML, CSS, JavaScript\\n  * Backend: Django\\n  * Database: SQLite\\n  * Data Scraping: Beautiful Soup\\n  * Data Cleaning: NumPy, Pandas\\n  * Data Visualization: Chart.js\\n## Command to run the project locally\\n  * python manage.py runserver\\n  * Then run the server locally on port 8000\\n## Home page\\nThe home page of the JOSAA Analysis portal provides a user-friendly interface\\nto explore and analyze the JOSAA seat allotment statistics. It offers several\\ninsightful sections to delve into the data and gain valuable information.\\nHere's a breakdown of each section: \\\\- View Institute wise cut-off \\\\- Analyze\\ninstitute wise cut-off trends \\\\- Roundwise cut-off Analysis\\n  * ![home](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/1d752e47-ef2d-4b4c-bf66-77fc8817c09d)\\n## View Institute wise cut-off list page\\n  * Upon clicking this option, a list of all IITs is shown along with their NIRF ranking(2023), Location and their established year. So the users can select specific institutes and explore the corresponding cut-off data.\\n  * ![iit list](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/f4f562e1-c93b-48a5-a114-4c321b296fe6)\\n    * ### For each IIT \\n      * By selecting a specific IIT, users can explore the trends and changes in the cut-off ranks throughout the various rounds of the seat allocation process over the years 2016 to 2022.\\n      * It can further narrow down their search by choosing specific programs offered by the selected institutes along with seat type and gender.\\n      * This feature helps users understand the cut-off trends for different programs in their preferred institutes.\\n      * ![first graph](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/5c411f78-ea17-4218-a0d6-9a8740ad78b5)\\n## Analyze institute wise cut-off trends\\n  * Institute trends highlight the trends of various programs offered by a particular institute over the years. This helps understand the popularity and perception of programs offered by the institute, and thus helps understand the demand for a particular program in the institute during the counselling process.\\n  * ![Screenshot \\\\(20\\\\)](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/45d3feab-6bf4-4611-91fb-91580b6a90ce)\\n  * Upon sleecting the gender, branch and institute, user will get the cut-off analysis for each branch present at that IIT.\\n  * ![Screenshot \\\\(22\\\\)](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/1db046fe-c44c-4627-8282-c8143bf0a88a)\\n## Roundwise cut-off Analysis\\n  * Round trends highlight the general trend of closing ranks throughout the rounds of the counselling process. This helps understand the likely range of changes to the closing ranks throught the counselling proces.\\n  * Users can get the round wise analysis at each IIT by selecting the gender,seat type and branch.\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 8, 'page_label': '9'}, page_content='* User can change the college name by clicking on \"Go to iit-list\" buttion.\\n  * ![Screenshot \\\\(25\\\\)](https://github.com/Vidya132/JOSAA-data-analysis/assets/95306028/3206dd19-d8fb-4e88-ace9-84a743db723e)\\nKidney_diease_end_to_end\\nupdated_at -> 2025-03-05\\ncreated_at -> 2025-03-05\\npushed_at -> 2025-03-05\\nPython, Jupyter Notebook,\\n# Kidney _diease_ end _to_ end\\n## Workflow\\n  1. Update config.yaml in config dir\\n  2. Update secrets.yaml [optional]\\n  3. Update params.yaml\\n  4. Update the entity\\n  5. Update the configuration manager in src config\\n  6. Update the components\\n  7. Update the pipeline\\n  8. Update the main.py\\n  9. Update the dvc.yaml\\n# To run the repo\\n## steps\\nClone the repository `bash\\nhttps://github.com/appsbotta/Kidney_diease_end_to_end `\\n## step - 01 Create a conda env after opening the repo\\n`bash conda create -n ckn python=3.8 -y ` `bash conda activate ckn `\\n## step - 02 Install Requirements.txt\\n`bash pip install -r requirements.txt `\\n## step - 03 Run app.py\\n`bash python app.py `\\n## DVC cmd\\n  * dvc init\\n  * dvc repro\\n  * dvc dag'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 9, 'page_label': '10'}, page_content='# AWS CI-CD Deployment using Github Actions\\n## 1\\\\. Login to AWS Console\\n## 2\\\\. Create IAM user for deployment\\n```bash\\n# give these access to IAM user\\n  1. EC2 access -> this is virtual machine\\n  2. ECR: Elastic COntainer registery to save your docker image in aws\\n# About deployment\\n  1. build docker image of the source code\\n  2. Push your docker image to ECR\\n  3. Launch your EC2 instance\\n  4. Pull your image from ECR to EC2\\n  5. Launch your docker image in EC2\\n# policy\\n  1. AmazonEC2ContainerRegistryFullAccess\\n  2. AmazonEC2FullAccess\\n```\\nLangChain\\nupdated_at -> 2025-03-12\\ncreated_at -> 2025-01-13\\npushed_at -> 2025-03-12\\nJupyter Notebook, Python,\\n# LangChain Projects\\nThis repository showcases various applications and experiments utilizing the\\nLangChain framework, which is designed for building applications powered by\\nlarge language models (LLMs).\\n## Table of Contents\\n  * Projects'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 10, 'page_label': '11'}, page_content='* LLMAPP\\n    * PdfQuery\\n    * ChatMultipleDocs\\n    * TextSummarization\\n    * Celebrity.py\\n  * Installation\\n  * Usage\\n  * Contributing\\n  * License\\n## Projects\\n### LLMAPP\\nA project demonstrating the integration of LangChain with large language\\nmodels to build intelligent applications.\\n### PdfQuery\\nAn application that utilizes LangChain to extract and process information from\\nPDF documents.\\n### ChatMultipleDocs\\nA chatbot implementation capable of interacting with multiple documents,\\npowered by LangChain.\\n### TextSummarization\\nA tool that leverages LangChain to provide text summarization capabilities.\\n### Celebrity.py\\nA script that explores web to get the data related to a Celebrity given his\\nname and any 5 major events happend around his DOB\\n## Installation\\n  1. **Clone the repository:**\\n```bash git clone https://github.com/appsbotta/LangChain.git cd LangChain\\n  2. **Create a virtual environment:**\\n```bash conda create -p myenv python conda activate path/to/myenv\\n  3. **Install the required dependencies:**\\n```bash pip install -r requirements.txt'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 11, 'page_label': '12'}, page_content='4. **Create a`.env` file in the root of the repository:**\\nAdd your API keys to the .env file ```bash touch .env\\n## Usage\\nEach project is contained within its respective directory. Navigate to the\\ndesired project folder and follow the instructions provided above\\nLlamaindex\\nupdated_at -> 2025-03-14\\ncreated_at -> 2025-01-17\\npushed_at -> 2025-03-14\\nJupyter Notebook,\\n# Llamaindex\\nMarket_Basket\\nupdated_at -> 2023-08-15\\ncreated_at -> 2023-08-15\\npushed_at -> 2023-08-15\\nJupyter Notebook,\\n# Market_Basket\\nThis notebook has been executed on kaggle. To view the notebook and run it,\\nhttps://www.kaggle.com/code/lokesh5489/market-basket To view the concerned\\ndataset, visit https://www.kaggle.com/code/lokesh5489/market-basket/data\\nUsed Aprior algorithm to find relation between two products\\nNetworks\\nupdated_at -> 2024-05-25\\ncreated_at -> 2024-05-23\\npushed_at -> 2024-05-25\\nC++, HTML, C,\\n# # The Network Simulator, Version 3\\n## Changes that we made\\n### 1.lte-ue-mac.cc\\n  * added one pre-defined table for type-0 allocation at line 52\\n  * Added Pf in line 404'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 12, 'page_label': '13'}, page_content='* Added function to get rbg size at line 503\\n  * line 2482 for grant printing in random allocation\\n  * line 2532 code for PF allocation, CQI calculation,mcs from cqi\\n  * added function at line 2715\\n### 2.lte-sl-out-of-covrg-comm.cc\\n  * At line 268 added code to print from rrc\\n  * At line 412 added code to print from mac\\nOlX_CLONE\\nupdated_at -> 2023-08-26\\ncreated_at -> 2023-08-26\\npushed_at -> 2023-08-26\\nJavaScript, CSS, HTML,\\n# OLX _clone_ IITG\\n## About the website\\nUsers are directed to login page on opening the website. Users have to login\\nusing their Outlook Id. Later user will be directed to home page of the\\nwebsite where two buttons will be displayed. Here user can choose whether to\\nbuy or sell and based on that available categories will be diplayed. Profile\\nshows logged in users profile. Logout button logs out the user.\\n## Environment Setup Locally\\n  * Install React\\n  * Use npm install in both Backend and Client \\n  * ...\\n## Tech Stack Used\\n  * React\\n  * MongoDB\\n  * Express\\n  * Node\\n  * HTML\\n  * CSS\\n  * Javascript\\n## Key Features\\n  * User can login and logout using Outlook Id\\n  * Functionality to buy and sell\\n  * Seller Profile Containing all the products he want to sell and stats of every deal he made, like people who are interested with listed money'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 13, 'page_label': '14'}, page_content='* Search functionality for buyer and filter method to get his wanted product within the desired price range\\n  * Product details along with buyer details\\n  * Option to agree to listed deal or to reach out seller for some negotiation for a particular product\\n  * Marks product as sold if deal is made\\n## Login page\\n  * The web application is authenticated and user must sign in using Outlook Id. ![image](https://user-images.githubusercontent.com/95306028/177820740-33b49604-b1b1-4285-bc41-9b9a5bf5b1ce.png)\\n## Home page\\n  * After login the home page will be displayed, where user can choose to buy or sell items. ![image](https://user-images.githubusercontent.com/95306028/177821314-90828c2c-6ef6-4644-9729-df123930b31c.png)\\n## Buyer Homepage\\n  * After clicking **Buy** all categories which are available are displayed. User can also search for required item in search bar.\\n  * ![image](https://user-images.githubusercontent.com/95306028/177822651-b505f91e-2f11-4826-951c-e6e6e0560d97.png)\\nPortifolio\\nupdated_at -> 2025-03-17\\ncreated_at -> 2025-01-18\\npushed_at -> 2025-03-17\\nJavaScript, HTML, CSS,\\n# Portifolio\\nQ-A_ChatBot_with_Implementation\\nupdated_at -> 2025-03-11\\ncreated_at -> 2025-01-07\\npushed_at -> 2025-03-11\\nPython,\\n* * *\\ntitle: LangChain ChatBot emoji: ■ colorFrom: gray colorTo: blue sdk: streamlit\\nsdk _version: 1.41.1 app_ file: app.py\\n## pinned: false\\nReal-Time-chatting\\nupdated_at -> 2022-06-30\\ncreated_at -> 2022-06-30\\npushed_at -> 2022-07-07\\nHTML, CSS, JavaScript,'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 14, 'page_label': '15'}, page_content=\"# Real-Time-chatting\\nUser are directed to opening page where ther need to click 'Enter ChatRoom',\\nUpon Clicking it users are redirected to a page where they need to enter then\\nroom,upon that the user will enter into chat room where he can chat with his\\nother buddies!!\\n## Enviroment Setup Locally\\n  * Install Web Sockets and Expressjs\\n  * Run the server and Connect to Port 500\\n## Tech Stack Used\\n  * HTML\\n  * JavaScript\\n  * Css\\n  * WebSockets\\n## Opening Page\\n  * This the Page we get when we Open localhost in port 5000\\n![OPENING](https://user-\\nimages.githubusercontent.com/75985363/177767489-6a32f337-8b3c-4281-a281-1d58c24ae3e0.jpg)\\n## Name Entry\\n  * User need to enter his name ![entering name](https://user-images.githubusercontent.com/75985363/177767789-5137808d-a34a-4bed-b415-b3ab67a61fca.jpg)\\n## Chat Room\\n  * After entering name User redirects to this page ![chat room](https://user-images.githubusercontent.com/75985363/177767981-0893a5eb-7aa2-4421-8bd1-da9592eeb46d.jpg)\\nSentimentAnalysis\\nupdated_at -> 2024-11-09\\ncreated_at -> 2024-11-09\\npushed_at -> 2024-11-09\\n# SentimentAnalysis\\nSimpleDVC\\nupdated_at -> 2025-02-24\\ncreated_at -> 2025-02-21\\npushed_at -> 2025-02-24\\nPython, Jupyter Notebook, HTML,\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 15, 'page_label': '16'}, page_content='# WorkFlow of the Project\\n  1. Create env `bash conda create -p myenv python -y `\\n  2. activate env `bash conda activate (path to myenv) `\\n  3. Create Requirements.txt\\n  4. Install requirements.txt `bash pip install -r requirements.txt `\\n  5. Initilize git `bash git init `\\n  6. Initilize DVC `bash dvc init `\\n  7. Add data to DVC `bash dvc add data_given/winequality.csv `\\n  8. `bash git add . && git commit -m \"first commit\" git push origin main `\\n  9. Create params.yaml\\n  10. create get _data.py and load_ data.py to get data and add the load_data stage to dvc.yaml\\n  11. create split _data.py to split data and add the split_ data stage to dvc.yaml\\n  12. create train _and_ evaluate.py to train & evaluate model and add the train _and_ evaluate stage to dvc.yaml\\n  13. Tox `bash tox tox -r #for rebuilding use this else only tox `\\n  14. pytest `bash pytest -v `\\n  15. setup command `bash pip install -e . `\\n  16. build your own package `bash python setup.py sdist bdist_wheel `\\n  17. create the need webapp structure\\n  18. Create app.py \\n  19. Add github action workflow\\n  20. Create an articat folder\\n  21. MLflow server command `bash mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 -p 1234 `\\nStockPrediction\\nupdated_at -> 2023-08-24\\ncreated_at -> 2023-08-24'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 16, 'page_label': '17'}, page_content='pushed_at -> 2023-08-24\\nJupyter Notebook,\\n# StockPrediction\\nThis notebook has been executed on kaggle. To view the notebook and run it,\\nvisit : https://www.kaggle.com/code/lokesh5489/stock\\nstudent_performance\\nupdated_at -> 2025-03-02\\ncreated_at -> 2025-02-28\\npushed_at -> 2025-03-02\\nJupyter Notebook, Python, HTML,\\n# End to End ML Project (student_performance)\\n## workflow\\n  1. created setup.py, template.py and requirements.txt\\n  2. Created custom exception in exception.py and logger.py and a function to read yaml\\n  3. created EDA and Model trainer in research\\n  4. Add new config.yaml file and done data_ingestion\\n  5. Completed data transformation\\n  6. Model Training\\n  7. Created the prediction pipeline and the Flask app\\n  8. Created .ebextensions for deployment\\n  9. create .github actions\\n  10. create ECR repo and save the repo uri \\n  11. create a ec2 instance \\n  12. Create a iam user and save a access key\\n  13. In github, in settings under action/runner create a new runner. a. while running the cmds in order when asked for runner group keep it default but for runner name use self-hosted\\n  14. Create Secret keys in github which are in workflow\\n## Docker Setup In EC2 commands to be Executed'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 17, 'page_label': '18'}, page_content='# optinal\\n  1. sudo apt-get update -y\\n  2. sudo apt-get upgrade\\n# required\\n  1. curl -fsSL https://get.docker.com -o get-docker.sh\\n  2. sudo sh get-docker.sh\\n  3. sudo usermod -aG docker ubuntu\\n  4. newgrp docker \\n## To run\\n  1. Create a virtual env and activate it `bash conda create -p env python y conda activate /path/to/env `\\n  2. Install requirements.txt `bash pip install -r requirements.txt `\\nTelecom_Churn_Prediction\\nupdated_at -> 2023-08-23\\ncreated_at -> 2023-08-23\\npushed_at -> 2024-02-14\\nJupyter Notebook,\\n# Telecom _Churn_ Prediction\\nThis notebook has been executed on kaggle for utilising its GPU feature. To\\nview the dataset, visit https://www.kaggle.com/code/lokesh5489/telecomm-\\nchurn/data To visit the notebook, visit\\nhttps://www.kaggle.com/code/lokesh5489/telecomm-churn/notebook\\nText-Summarizer\\nupdated_at -> 2025-03-16\\ncreated_at -> 2024-08-15\\npushed_at -> 2025-03-16\\nJupyter Notebook, Python, Dockerfile,\\n# End-to-End Text-Summarizer\\n## Workflows\\n  1. Update config.yaml'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 18, 'page_label': '19'}, page_content='2. Update params.yaml\\n  3. Update entity\\n  4. Update configuration manager in src/config\\n  5. Update components\\n  6. Update pipeline\\n  7. Update main.py\\n  8. Update app.py\\n# How to run?\\n### STEPS:\\nClone the repository\\n`bash https://github.com/appsbotta/Text-Summarizer.git `\\n### STEP 01- Create a conda environment after opening the repository\\n`bash conda create -n summary python=3.8 -y `\\n`bash conda activate summary `\\n### STEP 02- install the requirements\\n`bash pip install -r requirements.txt `\\n```bash\\n# Finally run the following command\\npython app.py ```\\nNow, `bash open up you local host and port `\\n# AWS-CICD-Deployment-with-Github-Actions\\n## 1\\\\. Login to AWS console.\\n## 2\\\\. Create IAM user for deployment\\n    \\n    \\n    #with specific access\\n    \\n    1. EC2 access : It is virtual machine\\n    \\n    2. ECR: Elastic Container registry to save your docker image in aws\\n    #Description: About the deployment'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 19, 'page_label': '20'}, page_content='1. Build docker image of the source code\\n    \\n    2. Push your docker image to ECR\\n    \\n    3. Launch Your EC2 \\n    \\n    4. Pull Your image from ECR in EC2\\n    \\n    5. Lauch your docker image in EC2\\n    \\n    #Policy:\\n    \\n    1. AmazonEC2ContainerRegistryFullAccess\\n    \\n    2. AmazonEC2FullAccess\\n    \\n## 3\\\\. Create ECR repo to store/save docker image\\n    \\n    \\n    - copy the repo uri\\n    - ex : 022499019910.dkr.ecr.us-east-1.amazonaws.com/text\\n    \\n## 4\\\\. Create EC2 machine (Ubuntu)\\n## 5\\\\. Open EC2 and Install docker in EC2 Machine:\\n    \\n    \\n    #optinal\\n    \\n    sudo apt-get update -y\\n    \\n    sudo apt-get upgrade\\n    \\n    #required\\n    \\n    curl -fsSL https://get.docker.com -o get-docker.sh\\n    \\n    sudo sh get-docker.sh\\n    \\n    sudo usermod -aG docker ubuntu\\n    \\n    newgrp docker\\n# 6\\\\. Configure EC2 as self-hosted runner:\\n    setting>actions>runner>new self hosted runner> choose os> then run command one by one'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 20, 'page_label': '21'}, page_content='# 7\\\\. Setup github secrets:\\n    \\n    \\n    AWS_ACCESS_KEY_ID=\\n    \\n    AWS_SECRET_ACCESS_KEY=\\n    \\n    AWS_REGION = us-east-1\\n    \\n    AWS_ECR_LOGIN_URI =\\'\\'(for example it will be 022499019910.dkr.ecr.us-east-1.amazonaws.com)\\n    \\n    ECR_REPOSITORY_NAME = \\'\\' (example text as last part of ECR uri)\\nVideo_Web\\nupdated_at -> 2023-08-26\\ncreated_at -> 2023-08-26\\npushed_at -> 2023-08-31\\nJavaScript, CSS, HTML,\\n# LuffyMeet - A Video chat web application\\n###  Intro\\nThis is a webRTC based video chatting web application. The users can register\\nand get logged in to their user page. They can either create a new room or use\\ntheir previous rooms to join a call and chat. This implementation also\\nconsists of a real time chat and file share functionality.\\n# Deployed link\\n[noobmeet.herokuapp.com](https://noobmeet.herokuapp.com/)  \\n(Calls and chats are functional, but becasue of NO \"Access-Control-Allow-\\nOrigin\" on icon package script, fonts-awesome is blocked. So u won\\'t be able\\nto access any incall-features in the deployement. To use all the features,\\nfollow the steps in \"Getting Started\" and run it on a local machine, no\\nproblems should arise, but depending on the time, the script source may\\nchange, so u have to manually change the source in local machine)\\n# Features and Functionalities\\n  * Unlimited number of rooms \\n  * Unlimited duration calls \\n  * Multiple participants \\n  * Copy the link and share it with your friends \\n  * Toggling your audio/video stream \\n  * Mute and Hide Everyone'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 21, 'page_label': '22'}, page_content='* Chat and File Share in real-time \\n  * Chat before and after the meeting \\n  * Send individual messages to the participants online in the room \\n  * Screen Sharing \\n  * Recording your stream, audio and video \\n  * Full Screen Mode on double click on the video \\n# ScreenShots\\n  * Login and Register page\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177010820-11f827e8-895b-4274-b568-d997184240d3.png)\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177010848-5471e60c-3261-49a3-9195-a380e0085db2.png)\\n  * Main Page\\n    * Contains all the past rooms in sorted according to the time of thier last update.\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177010985-a214ddf7-6ddb-42d7-8a66-a71e065fa1c4.png)\\n    * Creating a new room\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177011685-74a216e6-e020-4a17-906c-763c3d3c6682.png)\\n  * Call page\\n    * Call Page (videos are just turned off, it is functional)\\n![Screenshot \\\\(1074\\\\)](https://user-\\nimages.githubusercontent.com/72460532/177011233-1c00902c-9047-41ef-9f7f-f220a4bd9d9f.png)\\n    * Automatic pop up of chat box upon recieving an message. The chat box is draggable (hold the body instead of the bar). \\n![image](https://user-\\nimages.githubusercontent.com/72460532/177011335-d0d75476-c963-435b-9c38-a67f9439aab1.png)\\n  * Chat page - Contains all the chats form previous meetings.\\n![image](https://user-\\nimages.githubusercontent.com/72460532/177011551-15db10a1-ece1-4b9e-af36-86899d273424.png)\\nA more detailed description and ScreenShots will be uploaded soon. (With video\\nturned on too :-)).'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 22, 'page_label': '23'}, page_content='# Demo (Not functional as now)\\n  * Open https://noobmeet.herokuapp.com/\\n  * Create an account\\n  * Set a meeting name to create your room\\n  * Click on call button and give access to camera and microphone to join call\\n  * Click on chat button to chat before the meeting starts and as well as after the meeting ends\\n  * Share the room link for others to join \\n# Getting Started\\n  * You need to have Node.js installed\\n  * clone this repo\\n    * git clone https://github.com/fivar-rox/Video_chat.git\\n    * cd video-call\\n  * Install dependencies\\n    * npm init\\n    * npm install\\n  * Start the server \\n    * npm start\\n  * open http://localhost:4000 in your browser\\n# Tech Stack\\n  * Node.js \\n  * Web RTC \\n  * Socket.io \\n  * ngrok and stun-turn server\\n  * Firebase - for database \\n  * Heroku - for hosting'),\n",
       " Document(metadata={'producer': 'Microsoft® Excel® 2016', 'creator': 'Microsoft® Excel® 2016', 'creationdate': '2025-03-16T21:36:55+05:30', 'author': 'Lokesh Apparao Botta', 'moddate': '2025-03-16T21:36:55+05:30', 'source': 'artifacts\\\\data_transformation\\\\Skills.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Skills\\nEnd-to-End Project Management\\nContinuous Integration and Continuous Delivery (CI/CD)\\nAmazon Web Services (AWS)\\nMLOps\\nArtificial Intelligence (AI)\\nLarge Language Models (LLM)\\nAgentic AI\\nGoogle Gemini\\nGenerative AI\\nLangChain\\nNatural Language Processing (NLP)\\nData Science\\nTensorFlow\\nDeep Learning\\nMachine Learning\\nPython (Programming Language)\\nObject-Oriented Programming (OOP)\\nSQL\\nDjango\\npandas\\nNumPy\\nScikit-Learn\\nSoftware Development\\nData Structures\\nAlgorithms\\nMatplotlib\\nC++\\nReact.js\\nComputer networks\\nNode.js\\nCommunication\\nProject Management')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 10000,chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-17 19:42:12,077: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n",
      "[2025-03-17 19:42:13,051: INFO: loader: Loading faiss.]\n",
      "[2025-03-17 19:42:13,259: INFO: loader: Successfully loaded faiss.]\n",
      "[2025-03-17 19:42:13,276: INFO: __init__: Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents=documents,embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-17 19:42:17,812: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='f2a3ab13-6312-485b-b1c3-be6320eb4266', metadata={'producer': 'Microsoft® Excel® 2016', 'creator': 'Microsoft® Excel® 2016', 'creationdate': '2025-03-16T21:36:55+05:30', 'author': 'Lokesh Apparao Botta', 'moddate': '2025-03-16T21:36:55+05:30', 'source': 'artifacts\\\\data_transformation\\\\Skills.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Skills\\nEnd-to-End Project Management\\nContinuous Integration and Continuous Delivery (CI/CD)\\nAmazon Web Services (AWS)\\nMLOps\\nArtificial Intelligence (AI)\\nLarge Language Models (LLM)\\nAgentic AI\\nGoogle Gemini\\nGenerative AI\\nLangChain\\nNatural Language Processing (NLP)\\nData Science\\nTensorFlow\\nDeep Learning\\nMachine Learning\\nPython (Programming Language)\\nObject-Oriented Programming (OOP)\\nSQL\\nDjango\\npandas\\nNumPy\\nScikit-Learn\\nSoftware Development\\nData Structures\\nAlgorithms\\nMatplotlib\\nC++\\nReact.js\\nComputer networks\\nNode.js\\nCommunication\\nProject Management'),\n",
       " Document(id='8e637168-9460-42af-914c-4ff71ffe0181', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:16+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:16+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\last.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Portifolio last Updated at 2025-03-17 10:53:09\\nAI_Assistant last Updated at 2025-03-17 06:23:46\\nDataSets last Updated at 2025-03-16 16:15:56\\nText-Summarizer last Updated at 2025-03-16 14:30:46\\nLlamaindex last Updated at 2025-03-14 14:54:48\\nCrewAI last Updated at 2025-03-13 10:41:10\\nLangChain last Updated at 2025-03-12 07:26:04\\nQ-A_ChatBot_with_Implementation last Updated at 2025-03-11 14:50:44\\nAgenticAi last Updated at 2025-03-10 01:52:18\\nAWS_BEDROCK last Updated at 2025-03-07 03:27:03\\nKidney_diease_end_to_end last Updated at 2025-03-05 13:55:46\\nDL-End_to_End last Updated at 2025-03-05 11:42:04\\nstudent_performance last Updated at 2025-03-02 12:08:46\\nSimpleDVC last Updated at 2025-02-24 10:17:22\\nGemini last Updated at 2025-02-16 15:30:21\\nSentimentAnalysis last Updated at 2024-11-09 10:48:19\\nImageCaption last Updated at 2024-08-04 13:32:24\\nNetworks last Updated at 2024-05-25 02:45:05\\nJosaaDataAnalysis last Updated at 2023-08-28 13:46:23\\nFitnessTracker last Updated at 2023-08-27 13:35:23\\nVideo_Web last Updated at 2023-08-26 17:42:41\\nOlX_CLONE last Updated at 2023-08-26 17:17:42\\nStockPrediction last Updated at 2023-08-24 14:48:30\\nTelecom_Churn_Prediction last Updated at 2023-08-23 14:24:50\\nFaceDetection_React last Updated at 2023-08-19 16:47:01\\nMarket_Basket last Updated at 2023-08-15 12:15:14\\nReal-Time-chatting last Updated at 2022-06-30 05:18:21'),\n",
       " Document(id='1e0622ea-829d-44df-bbe7-669e12fc94ea', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 0, 'page_label': '1'}, page_content='1. AgenticAi ---> https://github.com/appsbotta/AgenticAi\\n2. AI_Assistant ---> https://github.com/appsbotta/AI_Assistant\\n3. AWS_BEDROCK ---> https://github.com/appsbotta/AWS_BEDROCK\\n4. CrewAI ---> https://github.com/appsbotta/CrewAI\\n5. DataSets ---> https://github.com/appsbotta/DataSets\\n6. DL-End_to_End ---> https://github.com/appsbotta/DL-End_to_End\\n7. FaceDetection_React --->\\nhttps://github.com/appsbotta/FaceDetection_React\\n8. FitnessTracker ---> https://github.com/appsbotta/FitnessTracker\\n9. Gemini ---> https://github.com/appsbotta/Gemini\\n10. ImageCaption ---> https://github.com/appsbotta/ImageCaption\\n11. JosaaDataAnalysis ---> https://github.com/appsbotta/JosaaDataAnalysis\\n12. Kidney_diease_end_to_end --->\\nhttps://github.com/appsbotta/Kidney_diease_end_to_end\\n13. LangChain ---> https://github.com/appsbotta/LangChain\\n14. Llamaindex ---> https://github.com/appsbotta/Llamaindex\\n15. Market_Basket ---> https://github.com/appsbotta/Market_Basket\\n16. Networks ---> https://github.com/appsbotta/Networks\\n17. OlX_CLONE ---> https://github.com/appsbotta/OlX_CLONE\\n18. Portifolio ---> https://github.com/appsbotta/Portifolio\\n19. Q-A_ChatBot_with_Implementation --->\\nhttps://github.com/appsbotta/Q-A_ChatBot_with_Implementation\\n20. Real-Time-chatting --->\\nhttps://github.com/appsbotta/Real-Time-chatting\\n21. SentimentAnalysis ---> https://github.com/appsbotta/SentimentAnalysis\\n22. SimpleDVC ---> https://github.com/appsbotta/SimpleDVC\\n23. StockPrediction ---> https://github.com/appsbotta/StockPrediction\\n24. student_performance --->\\nhttps://github.com/appsbotta/student_performance\\n25. Telecom_Churn_Prediction --->\\nhttps://github.com/appsbotta/Telecom_Churn_Prediction\\n26. Text-Summarizer ---> https://github.com/appsbotta/Text-Summarizer\\n27. Video_Web ---> https://github.com/appsbotta/Video_Web\\nAgenticAi\\nupdated_at -> 2025-03-10\\ncreated_at -> 2025-01-13\\npushed_at -> 2025-03-10'),\n",
       " Document(id='7ea8c60f-3202-4d98-9e5d-6f82c19243ee', metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-03-17T19:41:38+05:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-03-17T19:41:38+05:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'artifacts\\\\data_transformation\\\\repo.pdf', 'total_pages': 23, 'page': 15, 'page_label': '16'}, page_content='# WorkFlow of the Project\\n  1. Create env `bash conda create -p myenv python -y `\\n  2. activate env `bash conda activate (path to myenv) `\\n  3. Create Requirements.txt\\n  4. Install requirements.txt `bash pip install -r requirements.txt `\\n  5. Initilize git `bash git init `\\n  6. Initilize DVC `bash dvc init `\\n  7. Add data to DVC `bash dvc add data_given/winequality.csv `\\n  8. `bash git add . && git commit -m \"first commit\" git push origin main `\\n  9. Create params.yaml\\n  10. create get _data.py and load_ data.py to get data and add the load_data stage to dvc.yaml\\n  11. create split _data.py to split data and add the split_ data stage to dvc.yaml\\n  12. create train _and_ evaluate.py to train & evaluate model and add the train _and_ evaluate stage to dvc.yaml\\n  13. Tox `bash tox tox -r #for rebuilding use this else only tox `\\n  14. pytest `bash pytest -v `\\n  15. setup command `bash pip install -e . `\\n  16. build your own package `bash python setup.py sdist bdist_wheel `\\n  17. create the need webapp structure\\n  18. Create app.py \\n  19. Add github action workflow\\n  20. Create an articat folder\\n  21. MLflow server command `bash mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 -p 1234 `\\nStockPrediction\\nupdated_at -> 2023-08-24\\ncreated_at -> 2023-08-24')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"list all projects\"\n",
    "res = db.similarity_search(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import mlflow\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are Lokesh's personal AI assistant. You have been provided with a context that includes detailed information about Lokesh’s projects (project names, project URLs, updated_at, created_at, and pushed_at timestamps) as well as his personal details such as education, skills, and work experience.\n",
    "\n",
    "When a user asks a question related to Lokesh—whether it's about his projects, education, skills, or work experience—follow these guidelines:\n",
    "\n",
    "Use Only Provided Information:\n",
    "Answer strictly based on the context provided. Do not assume or add any external information.\n",
    "\n",
    "Detail and Accuracy:\n",
    "Extract and present accurate details from the context. For projects, include names, URLs, and date details as available.\n",
    "\n",
    "Step-by-Step Reasoning (if needed):\n",
    "If the question requires it, explain your reasoning by referring to the specific fields in the context.\n",
    "\n",
    "Insufficient Data Response:\n",
    "If the context does not have enough information to answer the question, reply exactly with:\n",
    "\"Sorry, I don't have access to that data yet.\"\n",
    "\n",
    "Now, answer the user's question based solely on the provided context.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "question:{input}\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019D96F936D0>, search_kwargs={'k': 30})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 30})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019D96F936D0>, search_kwargs={'k': 30}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nYou are Lokesh\\'s personal AI assistant. You have been provided with a context that includes detailed information about Lokesh’s projects (project names, project URLs, updated_at, created_at, and pushed_at timestamps) as well as his personal details such as education, skills, and work experience.\\n\\nWhen a user asks a question related to Lokesh—whether it\\'s about his projects, education, skills, or work experience—follow these guidelines:\\n\\nUse Only Provided Information:\\nAnswer strictly based on the context provided. Do not assume or add any external information.\\n\\nDetail and Accuracy:\\nExtract and present accurate details from the context. For projects, include names, URLs, and date details as available.\\n\\nStep-by-Step Reasoning (if needed):\\nIf the question requires it, explain your reasoning by referring to the specific fields in the context.\\n\\nInsufficient Data Response:\\nIf the context does not have enough information to answer the question, reply exactly with:\\n\"Sorry, I don\\'t have access to that data yet.\"\\n\\nNow, answer the user\\'s question based solely on the provided context.\\n\\n<context>\\n{context}\\n</context>\\nquestion:{input}\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000019DE73B7590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019D96F68910>, root_client=<openai.OpenAI object at 0x0000019D96F94E50>, root_async_client=<openai.AsyncOpenAI object at 0x0000019D96F68590>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retriever_chain = create_retrieval_chain(retriever,document_chain)\n",
    "retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_df):\n",
    "  answer = []\n",
    "  for index, row in input_df.iterrows():\n",
    "      answer.append(retriever_chain(row[\"questions\"]))\n",
    "\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "  {\n",
    "      \"questions\": [\n",
    "          \"who are you?\",\n",
    "          \"who is lokesh?\",\n",
    "          \"what is the highest education done by lokesh\",\n",
    "          \"what experience does lokesh have\",\n",
    "      ],\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.metrics.genai import EvaluationExample, faithfulness\n",
    "\n",
    "# Create a good and bad example for faithfulness in the context of this problem\n",
    "faithfulness_examples = [\n",
    "  EvaluationExample(\n",
    "      input=\"What is latest project lokesh worked on?\",\n",
    "      output=\"The latest project Lokesh worked on is the 'StockPrediction' project. This project was updated, created, and pushed to GitHub on August 24, 2023.\",\n",
    "      score=2,\n",
    "      justification=\"The output does not provides a working solution, provided in the context.\",\n",
    "      grading_context={\n",
    "          \"context\": \"\"\"\n",
    "          Portifolio updated_at -> 2025-03-17\n",
    "          StockPrediction updated_at -> 2023-08-24\n",
    "          \"\"\"\n",
    "      },\n",
    "  ),\n",
    "  EvaluationExample(\n",
    "      input=\"What is latest project lokesh worked on?\",\n",
    "      output=\"The latest project Lokesh worked on is the 'Portifolio' project. This project was updated, created, and pushed to GitHub on August 24, 2023.\",\n",
    "      score=5,\n",
    "      justification=\"The output provides a solution that is using the 18. Portifolio Section that is provided in the context.\",\n",
    "      grading_context={\n",
    "          \"context\": \"\"\"\n",
    "          Portifolio updated_at -> 2025-03-17\n",
    "          StockPrediction updated_at -> 2023-08-24\n",
    "          \"\"\"\n",
    "      },\n",
    "  ),\n",
    "]\n",
    "\n",
    "faithfulness_metric = faithfulness(model=\"openai:/gpt-4\", examples=faithfulness_examples)\n",
    "print(faithfulness_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-17 20:08:40,714: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n",
      "[2025-03-17 20:08:46,880: INFO: _client: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"]\n",
      "Lokesh's 2 latest projects based on the provided context are:\n",
      "\n",
      "1. **Portifolio**\n",
      "   - Project URL: https://github.com/appsbotta/Portifolio\n",
      "   - Last Updated at: 2025-03-17\n",
      "\n",
      "2. **AI_Assistant**\n",
      "   - Project URL: https://github.com/appsbotta/AI_Assistant\n",
      "   - Last Updated at: 2025-03-17\n",
      "\n",
      "These are the 2 most recently updated projects in Lokesh's portfolio.\n"
     ]
    }
   ],
   "source": [
    "res = retriever_chain.invoke({\"input\":\"what are his 2 latest projects\"})\n",
    "print(res['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 945554174,\n",
       " 'node_id': 'R_kgDOOFwC_g',\n",
       " 'name': 'AI_Assistant',\n",
       " 'full_name': 'appsbotta/AI_Assistant',\n",
       " 'private': False,\n",
       " 'owner': {'login': 'appsbotta',\n",
       "  'id': 75985363,\n",
       "  'node_id': 'MDQ6VXNlcjc1OTg1MzYz',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/75985363?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/appsbotta',\n",
       "  'html_url': 'https://github.com/appsbotta',\n",
       "  'followers_url': 'https://api.github.com/users/appsbotta/followers',\n",
       "  'following_url': 'https://api.github.com/users/appsbotta/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/appsbotta/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/appsbotta/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/appsbotta/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/appsbotta/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/appsbotta/repos',\n",
       "  'events_url': 'https://api.github.com/users/appsbotta/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/appsbotta/received_events',\n",
       "  'type': 'User',\n",
       "  'user_view_type': 'public',\n",
       "  'site_admin': False},\n",
       " 'html_url': 'https://github.com/appsbotta/AI_Assistant',\n",
       " 'description': None,\n",
       " 'fork': False,\n",
       " 'url': 'https://api.github.com/repos/appsbotta/AI_Assistant',\n",
       " 'forks_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/forks',\n",
       " 'keys_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/keys{/key_id}',\n",
       " 'collaborators_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/collaborators{/collaborator}',\n",
       " 'teams_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/teams',\n",
       " 'hooks_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/hooks',\n",
       " 'issue_events_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/issues/events{/number}',\n",
       " 'events_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/events',\n",
       " 'assignees_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/assignees{/user}',\n",
       " 'branches_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/branches{/branch}',\n",
       " 'tags_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/tags',\n",
       " 'blobs_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/git/blobs{/sha}',\n",
       " 'git_tags_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/git/tags{/sha}',\n",
       " 'git_refs_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/git/refs{/sha}',\n",
       " 'trees_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/git/trees{/sha}',\n",
       " 'statuses_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/statuses/{sha}',\n",
       " 'languages_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/languages',\n",
       " 'stargazers_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/stargazers',\n",
       " 'contributors_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/contributors',\n",
       " 'subscribers_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/subscribers',\n",
       " 'subscription_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/subscription',\n",
       " 'commits_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/commits{/sha}',\n",
       " 'git_commits_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/git/commits{/sha}',\n",
       " 'comments_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/comments{/number}',\n",
       " 'issue_comment_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/issues/comments{/number}',\n",
       " 'contents_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/contents/{+path}',\n",
       " 'compare_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/compare/{base}...{head}',\n",
       " 'merges_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/merges',\n",
       " 'archive_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/{archive_format}{/ref}',\n",
       " 'downloads_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/downloads',\n",
       " 'issues_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/issues{/number}',\n",
       " 'pulls_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/pulls{/number}',\n",
       " 'milestones_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/milestones{/number}',\n",
       " 'notifications_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/notifications{?since,all,participating}',\n",
       " 'labels_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/labels{/name}',\n",
       " 'releases_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/releases{/id}',\n",
       " 'deployments_url': 'https://api.github.com/repos/appsbotta/AI_Assistant/deployments',\n",
       " 'created_at': '2025-03-09T17:38:25Z',\n",
       " 'updated_at': '2025-03-11T03:40:40Z',\n",
       " 'pushed_at': '2025-03-11T03:40:37Z',\n",
       " 'git_url': 'git://github.com/appsbotta/AI_Assistant.git',\n",
       " 'ssh_url': 'git@github.com:appsbotta/AI_Assistant.git',\n",
       " 'clone_url': 'https://github.com/appsbotta/AI_Assistant.git',\n",
       " 'svn_url': 'https://github.com/appsbotta/AI_Assistant',\n",
       " 'homepage': None,\n",
       " 'size': 57,\n",
       " 'stargazers_count': 0,\n",
       " 'watchers_count': 0,\n",
       " 'language': 'Jupyter Notebook',\n",
       " 'has_issues': True,\n",
       " 'has_projects': True,\n",
       " 'has_downloads': True,\n",
       " 'has_wiki': True,\n",
       " 'has_pages': False,\n",
       " 'has_discussions': False,\n",
       " 'forks_count': 0,\n",
       " 'mirror_url': None,\n",
       " 'archived': False,\n",
       " 'disabled': False,\n",
       " 'open_issues_count': 0,\n",
       " 'license': {'key': 'mit',\n",
       "  'name': 'MIT License',\n",
       "  'spdx_id': 'MIT',\n",
       "  'url': 'https://api.github.com/licenses/mit',\n",
       "  'node_id': 'MDc6TGljZW5zZTEz'},\n",
       " 'allow_forking': True,\n",
       " 'is_template': False,\n",
       " 'web_commit_signoff_required': False,\n",
       " 'topics': [],\n",
       " 'visibility': 'public',\n",
       " 'forks': 0,\n",
       " 'open_issues': 0,\n",
       " 'watchers': 0,\n",
       " 'default_branch': 'main',\n",
       " 'permissions': {'admin': True,\n",
       "  'maintain': True,\n",
       "  'push': True,\n",
       "  'triage': True,\n",
       "  'pull': True}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "url = \"https://api.github.com/user/repos?per_page=100\"\n",
    "\n",
    "headers = {\"Authorization\": f\"token {TOKEN}\"}\n",
    "repos = requests.get(url, headers=headers).json()\n",
    "\n",
    "# for repo in repos:\n",
    "#     print(repo)\n",
    "repos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# TOKEN = os.getenv(\"TOKEN\")\n",
    "url = 'https://api.github.com/repos/appsbotta/ImageCaption/languages'\n",
    "\n",
    "headers = {\"Authorization\": f\"token {TOKEN}\"}\n",
    "lang = requests.get(url).json()\n",
    "\n",
    "# for repo in repos:\n",
    "#     print(repo)\n",
    "top_three_keys = sorted(lang, key=lang.get, reverse=True)[:3]\n",
    "top_three_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = f\"https://api.github.com/repos/appsbotta/LangChain/readme\"\n",
    "response = requests.get(readme)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Appsb\\\\Desktop\\\\AI_Assistant'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Appsb\\\\Desktop\\\\AI_Assistant'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('AI_Assistant')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.linkedin.com/in/lokesh5489/', 'language': 'No language found.'}, page_content='\\n\\n\\n')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'),temperature=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
